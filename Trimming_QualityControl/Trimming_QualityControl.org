#+LATEX_HEADER: \usepackage{grffile}
#+OPTIONS: tex:imagemagick

#+LATEX_HEADER: \usepackage[inline]{enumitem} 
#+LATEX_HEADER: \usepackage{tikz,graphicx, graphics, pgfkeys}
#+LATEX_HEADER: \usetikzlibrary{arrows,decorations.pathreplacing}
# #+LATEX_HEADER: \setdescription{style=multiline,leftmargin=3cm,font=\normalfont}

#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \hypersetup{
#+LATEX_HEADER:    colorlinks,
#+LATEX_HEADER:    linkcolor={red!50!black},
#+LATEX_HEADER:    citecolor={blue!50!black},
#+LATEX_HEADER:    urlcolor={blue!80!black}
#+LATEX_HEADER:}


#+LATEX_HEADER:\usepackage{setspace}%% The linestretch
#+LATEX_HEADER:\singlespacing

#+LATEX_HEADER:\usepackage[format=hang,indention=0cm,singlelinecheck=true,justification=raggedright,labelfont={normalsize,bf},textfont={normalsize}]{caption} % 


#+LATEX_HEADER:\usepackage{vmargin}
#+LATEX_HEADER:\setpapersize{A4}
#+LATEX_HEADER:\setmarginsrb{2.5cm}{1cm}% links, oben
#+LATEX_HEADER:                                                {2.5cm}{2cm}% rechts, unten
#+LATEX_HEADER:                                                {12pt}{30pt}% Kopf: Höhe, Abstand
#+LATEX_HEADER:                                                {12pt}{30pt}% Fuß: Höhe, AB     
                                                

# #+LATEX_HEADER:\usepackage[babel,english=british]{csquotes}

# #+LATEX_HEADER:% English quotes are used.                                       

#+LATEX_HEADER: \usepackage{upquote}
                                        
# #+LATEX_HEADER:\usepackage[english]{babel}                                     

                                
#+LATEX_HEADER: %  use straight quotes when printing a command in minted

#+LATEX_HEADER: \AtBeginDocument{%
#+LATEX_HEADER: \def\PYZsq{\textquotesingle}%
#+LATEX_HEADER: }     

#+LATEX_HEADER: \setlength{\parindent}{0pt}
#+LATEX_HEADER: \setlength{\parskip}{\baselineskip}

#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \definecolor{mintedbackground}{rgb}{0.85,0.85,0.85}


#+TITLE: *Trimming and quality control* (May 2017)
#+AUTHOR: Alexander Jueterbock, Martin Jakt
#+DATE: *PhD course: High throughput sequencing of non-model organisms*
#+EMAIL: Nord University, Norway
#+OPTIONS: toc:t H:3 email:t author:t num:t creator:t ':nil


#+name: setup-minted
#+begin_src emacs-lisp :exports results :results silent
(setq org-latex-listings 'listings)
(setq org-latex-listings 'minted)
(setq org-latex-custom-lang-environments
        '((emacs-lisp "common-lispcode")))

(setq org-latex-minted-options
      '(("fontsize" "\\scriptsize")
        ("bgcolor=lightgray")
        ("linenos" "")))

(setq org-latex-to-pdf-process
           '("pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"
             "pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"
             "pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"))	      
#+end_src


# Overview of export options in http://orgmode.org/manual/Export-settings.html#Export-settings
After a general introduction to the UNIX command line, it is time for
you to analyze your own fastq files. The first important step for any
kind of sequencing data is to get rid of adapter contamination and 
bad quality reads. In this tutorial we will use the programs [[http://www.bioinformatics.babraham.ac.uk/projects/fastqc/][FastQC]]
and [[http://www.bioinformatics.babraham.ac.uk/projects/trim_galore/][TrimGalore!]] to check the quality of the sequenced libraries before
and after trimming.


*IMPORTANT NOTE* Before you get started: to compare characteristics of
your libraries, please keep record of the resulting numbers, like the
number of raw reads, reads after quality control, number of mapped
reads etc. This helps to identify peculiarities/outliers in your
libraries which may either be due to biological peculiarities of your
species or unknown technical issues.


Log on (with =ssh=) to the remote computer with the =-X= option (like
=ssh -X user@158...=) to be able to use graphical interfaces.

* Overview of sequence lengths
Next Generation Sequencing data is generally stored in fastq
files. Most of the time the data are compressed, either in .zip or in
.gz format.

If your file is zip-compressed, you can use the following command to unzip it:

#+begin_src sh
unzip FILE.fastq.zip
#+end_src

If your file iz gz-compressed, use the following command instead:

#+begin_src sh
gunzip FILE.fastq.gz
#+end_src

*NOTE*: For paired-end sequencing from Illumina, you have two
files. One file with the forward reads (=Sequence_R1.fq=) and one file with
the reverse reads (=Sequence_R2.fq=).


To get a quick impression of the minimum and maximum read lengths in
your fastq file, you can use the following commands (replace
=FILE.fastq= with your own filename):

#+begin_src sh
awk '{if(NR%4==2) print length($0)}' FILE.fastq| sort -n | head -n1
awk '{if(NR%4==2) print length($0)}' FILE.fastq| sort -n | tail -n1
#+end_src

It reads like this: measure the length of every second line in every
group of 4 lines (the sequence line in a fastq file), =sort= it
(numerically with =-n=) and print out either the first (smallest)
value with =head= or the last (biggest) value with =tail=. =NR=
represents the current line number and the =%= sign is the modulus
operator, which divides the line number by 4 (=NR%4=) and returns only
the remainder. This extracts all the sequences, which are on line
2,6,10,14...


The following command allows you to count the sequence lengths:

#+begin_src sh
awk '{if(NR%4==2) print length($0)}' FILE.fastq | sort -n | uniq -c > read_length.txt
#+end_src

The lines that follow make use of the program R. If you copy and
paste the code into the command line, you will get an overview graphic
of the sequence length distribution 

#+begin_src sh
cat >> Rplot.r << 'EOF'
reads<-read.csv(file="read_length.txt", sep="", header=FALSE)

png(filename = "SequenceLengthDistribution.png",
         width = 480, height = 480, units = "px", pointsize = 12,
          bg = "white")
plot(reads$V2,reads$V1,type="l",xlab="read length",ylab="occurences",col="blue")
dev.off()

EOF


R CMD BATCH Rplot.r
#+end_src

You can open the created figure with the GNOME image viewer using the
following command:

#+begin_src sh
eog SequenceLengthDistribution.png
#+end_src


#+CAPTION: Example graphic of the length distribution in a fastq file
#+ATTR_LaTeX: :width 10cm :float figure
[[file:SequenceLengthDistribution.png]]

Does the sequence length-distribution meet your expectations? 

*NOTE*: While the Ion Torrent sequences will differ in length (as in
Figure 1), the Illumina sequences will all have the same read length
(301 bp). 


* Quality control
To inspect the quality of the sequencing data, we use
[[http://www.bioinformatics.babraham.ac.uk/projects/fastqc/][FastQC]]. In
the installation and setup instructions of the program
([[http://www.bioinformatics.babraham.ac.uk/projects/fastqc/INSTALL.txt][link]]),
you will find that FastQC can run in an interactive mode or in a
command line mode. This tutorial uses the command-line version.

FastQC knows a number of standard adapter sequences used for HTS,
including adapters used on Illumina platforms; To get an overview of
the contaminants (overrepresented sequences) that FastQC will look
for by default, type

#+begin_src sh
less /usr/share/fastqc/Contaminants/contaminant_list.txt
## or possibly:
less /usr/local/fastqc/FastQC_v0.11.3/Configuration/contaminant_list.txt
#+end_src

However, FastQC is not aware of the sequences used by the IonTorrent
platform. To inform FastQC of the Ion Torrent adapter sequences
call FastQC with the =--contaminants= option to specify a file
containing the adapter sequences we have used.

So, to run FastQC on your file, type:

#+begin_src sh
fastqc --contaminants adapters.txt FILE.fastq
#+end_src

The adapters.txt file contains the adapter sequences in a
name[tab]sequence format, like

#+begin_src sh
IonTorrentAAdapter	CCATCTCATCCCTGCGTGTCTCCGACTCAG
IontTorrentP1Adapter	CCACTACGCCTCCGCTTTCCTCTCTATGGGCAGTCGGTGAT
#+end_src

You can create this file on the adapters.txt file on the remote computer with:

#+begin_src sh
touch adapters.txt
#+end_src

Open the text file with the program nano:

#+begin_src sh
nano adapters.txt
#+end_src

Then copy and paste the name-sequence combinations of the Ion Torrent
adapters (see above) into the file and close the file by pressing
Ctrl+O, then Ctrl+X on your keyboard.

The output of the FastQC program will be saved in a folder that has
the name of your fastq file and ends with fastqc, like
=FILE_fastqc=. Use the =cd= command to move into the folder and open
the produced =fastqc_report.html= either with =firefox= or
=chromium-browser= (one of the two should work).

#+begin_src sh
cd FILE_fastqc
firefox fastqc_report.html
chromium-browser fastqc_report.html
#+end_src

Scrolling through this html file on the remote computer will be quite
slow. it may be more convenient to copy the output folder to your
computer with [[https://filezilla-project.org/][FileZilla]] or 'rsync' (see in the 'Unix tools' session) .
Get familiar with the output of each module.

# Tor Erik informed me that they will use the IonPGM HiQ Ion Sphere
# protocol, which targets a library size of 400bp + adapters.

For example, it is normal that the the per base sequence quality drops
towards the end of the read, as seen in Figure 2. In the next section
we will see how to trim away these low-quality reads.

#+CAPTION: Per base sequence quality (from [[http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/2%20Per%20Base%20Sequence%20Quality.html][link]])
#+ATTR_LaTeX: :width 10cm :float figure
[[file:per_base_quality.png]]

The figure on duplication levels (Figure 3) informs you about the
percentage of duplicate reads in your sequenced library.  Duplicates
result from primer or PCR bias towards these reads.  As they can skew
genotype estimates, we will remove duplicate reads later in the week
before SNP calling.

#+CAPTION: Per base sequence quality (from [[http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/8%20Duplicate%20Sequences.html][link]])
#+ATTR_LaTeX: :width 10cm :float figure
[[file:duplication_levels.png]]

You can find guidance on how to interpret the output of each module
[[http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/][here]] 

* Trimming low quality reads and adapters
[[http://www.bioinformatics.babraham.ac.uk/projects/trim_galore/][TrimGalore!]] is a wrapper script to automate quality and adapter
trimming as well as quality control ([[http://www.bioinformatics.babraham.ac.uk/projects/trim_galore/trim_galore_User_Guide_v0.3.7.pdf][User Guide]]).

When the program is installed, it can be used with 

#+begin_src sh
trim_galore [options] <filename(s)>
#+end_src

You can get an overview of the options with the =--help= option:

#+begin_src sh
trim_galore --help
#+end_src

With the default settings, TrimGalore! trims low-quality ends with a
Phred quality score threshold of 20 (can be changed with =-q=) and
discards reads that become shorter than 20 bp (can be changed with
=--length=).

TrimGalore! uses the program [[https://code.google.com/p/cutadapt/][Cutadapt]] to find and remove adapters from
the 3' end of the reads (see Fig. [[fig:adapters]]). The program Cutadapt
itself gives you more options for adapter trimming and allows you to
remove adapters also from the 5'-end of the sequence (see
http://cutadapt.readthedocs.org/en/latest/guide.html)

#+CAPTION: 3'- and 5'-adapter trimming ([[http://cutadapt.readthedocs.org/en/latest/guide.html][source]])
#+ATTR_LaTeX: :width 14cm :float figure
#+name: fig:adapters
[[file:adapters.png]]

** Trimming Ion-Torrent adapters

The Ion-P1- and Ion-A-adapters are supposed to be automatically
trimmed off on the Ion Server. So, the fastq files with the raw reads
should not contain these adapters anymore. Still, it is good to check
if there are any adapters left in your library - they can have
negative effects on further analyses.



The adapters used for Ion Torrent sequencing are shown in
Fig. [[fig:ionadapters]] and their orientation in the libraries is shown
in Fig. [[fig:adapterorientations]].

#+name: fig:ionadapters
#+CAPTION: Non-barcoded Ion-A and -P1 adapter sequences. In each sequence, a "*" indicates a phosphorothioate bond, for protection from nucleases and to preserve the directionality of adapter ligation. This is not relevant for adapter trimming.
#+ATTR_LaTeX: :width 14cm :float figure
[[file:IonAdapters.png]]

#+name: fig:adapterorientations
#+CAPTION: Ion adapters in the amplified library. BC is an optional barcode sequence.
#+ATTR_LaTeX: :width 14cm :float figure
[[file:IonLibraryWithAdapters.png]].

To trim off the A-adapter, use TrimGalore! with the command:

#+begin_src sh
trim_galore \
-a CCATCTCATCCCTGCGTGTCTCCGACTCAG \
--stringency 3 \
FILE.fastq
#+end_src


The =\= sign just means that the command continues on the next
line. You could type the entire command on a single line.


The option =--stringency 3= means that a >3bp overlap with the adapter
sequence will be trimmed off the 3' end. The program writes a file
that ends with =trimming_report.txt=, which reports the number of
reads that have been trimmed and/or removed.

# XX I can't find information on what the 'expected' is based on in this report fiel 
The output file has the ending =trimmed.fq=. Use this file as
input to TrimGalore! to trim off the P1-adapter:

#+begin_src sh
trim_galore \
-a CCACTACGCCTCCGCTTTCCTCTCTATGGGCAGTCGGTGAT \
--stringency 3 \
--fastqc FILE_trimmed.fq
#+end_src

The =--fastqc= option will automatically run FastQC in the default
mode. Compare the FastQC outputs before and after trimming.


#+begin_latex
\clearpage
#+end_latex

** Trimming Illumina adapters
Depending on the settings for Illumina sequencing, the adapters can be
automatically removed from the fastq files that you get from the
sequencing machine. This, however, has to be defined before
sequencing. If you are not sure whether adapters have been trimmed off
or not, it is safe to trim the adapters before using the sequences for
any further analyses.

The Illumina adapters are as follows:

#+begin_src sh
TruSeq Universal Adapter:
5' AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT 3'

TruSeq Indexed Adapter
5' P*GATCGGAAGAGCACACGTCTGAACTCCAGTCACNNNNNNATCTCGTATGCCGTCTTCTGCTTG 3'
#+end_src

Here, =NNNNNN= represents a barcode of six nucleotides in the indexed adapter.

TrimGalore! can be run with the option =--illumina=. This trims the
first 13bp of the Illumina universal adapter =AGATCGGAAGAGC=. This
option removes illumina adapters from most standard libraries,
including TruSeq adapters.

The location of this sequence in the TruSeq adapter is shown here:

#+begin_src sh
TruSeq Universal Adapter:
5' AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT 3'
   Reverse                                      CGAGAAGGCTAGA 

TruSeq Indexed Adapter
5' P*GATCGGAAGAGCACACGTCTGAACTCCAGTCACNNNNNNATCTCGTATGCCGTCTTCTGCTTG 3'
    AGATCGGAAGAGC
#+end_src

The A on the 5'-end of the TruSeq indexed adapter is added during
A-tailing of your DNA library fragments.
The orientation of the adapters in the illumina library are shown in Fig. [[fig:illuminaadapters]].
#+name: fig:illuminaadapters
#+CAPTION: Orientation of the illumina adapters around the DNA inserts
#+ATTR_LaTeX: :width 17cm :float figure
[[file:IlluminaAdaptersVisualized.pdf]]


TrimGalore! also performs trimming of paired-end libraries, like the
Illumina libraries that were prepared in this course. This allows us to
discard read pairs without disturbing the sequence order of
FastQ files which is required by many aligners.  With the option
=--paired= TrimGalore! expects two paired fastq input files, like
=file1_1.fq= and =file1_2.fq=.  Here, both sequences of a sequence
pair must have a certain minimum length (specified by the =--length=
option) in order to be kept. If only one of the two paired end reads
becomes too short, the option =--retain_unpaired= can be applied to
write the long-enough unpaired read to either =unpaired_1.fq= or
=unpaired_2.fq=. The length cutoff for unpaired single end reads is
governed by the parameters =--length_1= and =--length_2=

To trim our illumina paired-end libraries we can use:

#+begin_src sh
trim_galore \
--illumina \
--stringency 3 \
--paired \
--retain_unpaired \
--length_1 21 \
--length_2 21 \
--fastqc \
Illumina_R1.fastq \
Illumina_R2.fastq 
#+end_src

This command runs fastqc automatically on the trimmed libraries. In addition
to the =fastqc.html= files, you will find fastq files with the validated
sequences (=Illumina_R1_val_1.fq=, =Illumina_R2_val_2.fq=) and with the
unpaired sequences (=Illumina_R1_unpaired_1.fq=, =Illumina_R2_unpaired_2.fq=).
The files ending with =trimming_report.txt= provide information on the number
of reads that have been trimmed and/or removed.

You can now compare the quality of your raw libraries and your
quality-trimmed libraries. What did improve? Are there still any
problems with your libraries after trimming?

* COMMENT Fraction of duplicate reads

Duplicate reads (identical reads present more than once in the
library) can skew genotype estimates and thus should be identified and
removed before SNP calling. Duplicates can result from primer or PCR
bias towards these reads and poor libraries can have levels of
duplicates >50%.

At this step, we will calculate the fraction of duplicates but we will
remove them only after /de novo/ genome assembly and read mapping.
The approach is based on the [[http://sfg.stanford.edu/SFG.pdf][Simple fool's guide to population
genomics via RNAseq]] and makes use of =fastx_collapser= from the
[[http://hannonlab.cshl.edu/fastx_toolkit/][FASTX-Toolkit]] and a python script (=fastqduplicatecounter.py=).

First, use =fastx_collapser= to combine and count all identical reads.

#+begin_src sh
fastx_collapser -Q 33 -v -i INPUTFILE.fq -o OUTPUTFILE.txt
#+end_src

The =INPUTFILE= is your trimmed fastq file. =-Q 33= specifies that
quality scores are Phred33 encoded.  The =OUTPUTFILE= is used in the
next step with the python script 'fastqduplicatecounter.py'.

#+begin_src sh
fastqduplicatecounter.py OUTPUTFILE.txt OUTPUTFILE_header.txt > OUTPUTFILE_duplicatecount.txt
#+end_src

This script calculates the fractions of duplicate and singleton
reads. Open the outputfile with =less OUTPUTFILE_duplicatecount.txt=
and check the percentage of duplicate reads.
* BONUS Running programs in the background with =nohup=
What if your data analysis on a remote server takes several hours,
days, or even weeks, to finish? No worries, you don't need to be
connected to the remote server while the data are being
analysed. Here, you will learn the tools that allow you to start
an analysis, disconnect from the server, and then look at the progress
or the results at a later time point.

The =nohup= tool allows you to run a process in the background; which
means that, while the analysis is running, you can do other tasks in
parallel or log off from the remote server.

Imagine the =nohup= tool as a bracket which encloses the command that
you want to run in the background:

#+begin_src sh
nohup ... &
#+end_src

Always, =nohup= precedes and =&= follows the command that you want to
run in the background (here shown as =...=). Let's say you want to run
the command =ls -lhcrt= (which lists all files and subdirectories in
your current directory) in the background.

#+begin_src sh
nohup ls -lhcrt &
#+end_src

When you hit ENTER, the terminal prints out some information:

#+begin_src sh
[1] 21118
nohup: ignoring input and appending output to 'nohup.out'
#+end_src

The number =21118= (which will differ in your case) in the first line
is the process-ID of your background-process. The second line informs you that
all 'results', that would be normally printed in the terminal window,
are now redirected to the file =nohup.out=. 

** Using the process-ID
If you have started a process that takes several hours
to finish, then you can use the process-ID to see if the process is
still running. For this, you can use the =ps= command with the =-p=
option, which reports the status of a process with a certain process
ID. To see the status of the process I have started above, I would
use:

#+begin_src sh
ps -p 21118
#+end_src

The output is

#+begin_src sh
PID TTY          TIME CMD
#+end_src

Since this is only the header line of the process specifications, the
process must have finished. 
Here:
- =PID= indicates the process-ID
- =TTY= indicates the controlling terminal
- =TIME= shows the time that the process is running already
- =CMD= shows the command name

If the process would still run, you would
get a line similar to:

#+begin_src sh
PID  TTY          TIME CMD
21118 ?        00:00:04 ls
#+end_src

The =top= tool provides an ongoing look at processor activity in real
time, similar to Figure [[fig:top]].


#+CAPTION: Screenshot of the =top= tool output
#+name: fig:top
#+ATTR_LaTeX: :width 10cm :float figure
[[file:top.png]]

At the top of the screen, it lists processes ordered by their CPU usage
system (with the most intensive on top). Besides other information, it shows which user is running
which process, as well as the process-ID. You can quit the program by
hitting =q=.

The process-ID also allows you to cancel the process before it
finishes. Cancelling processes comes in handy when you figure out
that you started them with the wrong parameters or input files and you want
to re-start with different settings. The =kill= command allows you
to cancel a specific process.

#+begin_src sh
kill 21118
#+end_src

This would cancel the process that we started before in the
background. If you can't remember the process-ID but want to cancel
all =ls= processes, then you could use the =pkill= command in the
following way:

#+begin_src sh
pkill ls
#+end_src

Compared to the =kill= command, the =pkill= command allows you to
specify the command-name instead of the process-ID of the running
process that you want to cancel.

If you don't have a record of the PID you can find out the id of processes being run by a specific user
by combining =ps= and =grep=:

#+begin_src sh
ps aux | grep user_name
#+end_src

where =user_name= is your own user name. That will list all processes started by
you (well using your id in any case). The =aux= option specifies all processes and
the manner in which these are printed out. If you read the man file (=man ps=) you
will see that there are ways in which you can get ps to only list processes started
by the current user (=ps -eu=) in a similar manner and that =ps aux= is BSD syntax.
So =grep= isn't really needed here, but I tend to like the way this formats the output.

** Redirecting output
By default, the =nohup= command redirects all information from the
terminal window to the =nohup.out= file. If the file exists already,
it will not be overwritten. All new information will be appended to
the end of the file. With the =>= operator, you can redirect the
output to a different file. For example, to redirect the output of the
=ls= command to the file =Directory-Listing.txt=, you can use the
command

#+begin_src sh
nohup ls -lhcrt > Directory-Listing.txt &
#+end_src

So, the redirection-operator (=>=) is followed by the name of the
target file and precedes the closing =&= operator of the =nohup=
command. If you want to save the output to a file in a different
directory, just specify the entire file-path that precedes your target
file, like:

#+begin_src sh
nohup ls -lhcrt > /home/alj/Documents/DirectoryListing.txt &
#+end_src




