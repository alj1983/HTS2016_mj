#+LATEX_HEADER: \usepackage{grffile}



#+LATEX_HEADER: \usepackage[inline]{enumitem} 
# #+LATEX_HEADER: \setdescription{style=multiline,leftmargin=3cm,font=\normalfont}

#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \hypersetup{
#+LATEX_HEADER:    colorlinks,
#+LATEX_HEADER:    linkcolor={red!50!black},
#+LATEX_HEADER:    citecolor={blue!50!black},
#+LATEX_HEADER:    urlcolor={blue!80!black}
#+LATEX_HEADER:}


#+LATEX_HEADER:\usepackage{setspace}%% The linestretch
#+LATEX_HEADER:\singlespacing

#+LATEX_HEADER:\usepackage[format=hang,indention=0cm,singlelinecheck=true,justification=raggedright,labelfont={normalsize,bf},textfont={normalsize}]{caption} % 


#+LATEX_HEADER:\usepackage{vmargin}
#+LATEX_HEADER:\setpapersize{A4}
#+LATEX_HEADER:\setmarginsrb{2.5cm}{1cm}% links, oben
#+LATEX_HEADER:                                                {2.5cm}{2cm}% rechts, unten
#+LATEX_HEADER:                                                {12pt}{30pt}% Kopf: Höhe, Abstand
#+LATEX_HEADER:                                                {12pt}{30pt}% Fuß: Höhe, AB     

#+LATEX_HEADER: %  use straight quotes when printing a command in minted

#+LATEX_HEADER: \AtBeginDocument{%
#+LATEX_HEADER: \def\PYZsq{\textquotesingle}%
#+LATEX_HEADER: }     

#+LATEX_HEADER: \setlength{\parindent}{0pt}
#+LATEX_HEADER: \setlength{\parskip}{\baselineskip}

#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \definecolor{mintedbackground}{rgb}{0.85,0.85,0.85}


#+TITLE: *Unix Tools for Bioinformatics* (May 2017)
#+AUTHOR: Martin Jakt, Alexander Jueterbock
#+DATE: *PhD course: High throughput sequencing of non-model organisms*
#+EMAIL: Nordland University, Norway

# the following line means that underscores do not automatically
# indicate subscript. 
#+OPTIONS: ^:{}
#+OPTIONS: toc:t H:3 email:t author:t num:t creator:nil ':nil

# Overview of export options in http://orgmode.org/manual/Export-settings.html#Export-settings


#+name: setup-minted
#+begin_src emacs-lisp :exports results :results silent
(setq org-latex-listings 'listings)
(setq org-latex-listings 'minted)
(setq org-latex-custom-lang-environments
        '((emacs-lisp "common-lispcode")))

(setq org-latex-minted-options
      '(("fontsize" "\\scriptsize")
        ("bgcolor=mintedbackground")
        ("linenos" "")))

(setq org-latex-to-pdf-process
           '("pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"
             "pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"
             "pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"))
	      
#+end_src





Next Generation Sequencing (NGS) data sets are big and although the data is
often text based you
simply can't open and work with them in a word processor or Excel
table - even the attempt to open a big fasta file in a word processor can
freeze your computer. Rather more importantly, even if you could, you
shouldn't as word processors are not the same as text editors. Word
processors are concerned more with the formatting of text and will store a
great deal of additional information in addition to the text that you
see. This additional information is irrelevant to the data and will in the
best case scenario make further analysis impossible. Similarly try to avoid
spreadsheets of various kinds as these almost always will try to interpret
and convert your data to something like dates or currencies or something similar.

At first, you might feel uncomfortable with the
command line but it is a very efficient and powerful tool. Moreover,
many programs to analyze NGS data can only be used from the command line and to
run them, you need to know the basic syntax. This tutorial gets you
familiar with some of the most basic command line tools and shows
you how they allow you to transfer files and how to extract
information from big files fast and easily. All tools and programs are
open source - so you will have free access to them also at your home
institution or on your private computer.


* Remote connection 
To connect remotely to one of our computers, you will get:

- A password (e.g. PWD213)
- A username (e.g. user)
- An IP address (e.g. 127.0.0.1)

On 'Mac' and 'Linux' computers, the =ssh= (/Secure Shell/) tool is
generally installed by default. To connect to a remote server, thus,
just open the command line/terminal and type:

#+begin_src sh 
ssh user@host
#+end_src


Replace 'user' and the IP address 'host' with your own
username and the IP address of one of our remote computers.

- IP Address: 158.39.30.163

If this is the first time you want to access the remote server, you
will likely get the following warning

#+begin_src console
The authenticity of host '127.0.0.1 (127.0.0.1)' can't be established.
ECDSA key fingerprint is 38:59:f7:22:e5:85:ec:c3:9c:90:7x:c3:e4:ae:88:18.
Are you sure you want to continue connecting (yes/no)? 
#+end_src

Just type 'yes' and hit enter[fn:: This is an oversimplification. In general you should not simply
ignore warnings like this, but it's too much off topic for us to
explain here. Note though, that you shouldn't see this warning more
than once, and if you do, you might want to read up on
'man-in-the-middle attacks'.]. You will be asked to enter your
password. You will not see the password when you enter it, so just
type it blindly and hit enter.

#+begin_src console
user@127.0.0.1's password:
#+end_src

When you connected successfully, you will see a /welcome-text/ similar to:

#+begin_src console
Welcome to Ubuntu 14.04.1 LTS (GNU/Linux 3.13.0-35-generic x86_64)
#+end_src


If you have a Windows based computer you will (probably) need to install a third
party program to provide ssh access. The easiest option is to download the
[[http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html][PuTTY]] program and then either install it (may need Administrator privileges) or
run it directly from the downloaded directory. PuTTY provides programs both
for ssh access and sftp file transfers between a Windows computer and a remote
host.

Alternatively, if you have a sufficiently new version of Windows 10, then you can install
and enable the "Windows Subsystem for Linux" feature (also known as "Bash on Windows").
This installs a complete Ubuntu command line interface as a subsystem and allows
you to use almost all of the command line tools that we will use here. We (the authors)
have no personal experience with this system at this time, but expect that it
would be useful if you have to run Windows on your own computer. Installation
instructions can be found from the [[https://msdn.microsoft.com/en-us/commandline/wsl/install_guide][Microsoft Developer Network website]]. If
you install this you should be able to run the =ssh= client from a bash session
as described for Linux and MacOS.

If you don't want to only use the command line on the remote host, but
also want to use the Graphical User Interface (GUI) to open figures or
GUI-based programs or web browsers, you should add the -X option to
your command:

#+begin_src sh
ssh -X user@host
#+end_src

If you use PUTTY on Windows you need to install Xming
(http://www.straightrunning.com/XmingNotes/) and follow the guidelines
on http://www.geo.mtu.edu/geoschem/docs/putty_install.html).

To open applications with a graphical user interface remotely on a
MAC, you need to install [[http://xquartz.macosforge.org/landing/][XQuartz]].

There are also a range of other options that let you access Unix/Linux
servers from Macs or Windows that will let you use the command line. However,
these often require specific software to be installed on the server and you
can't rely on these being present. In general, life is just easier if you run
Linux on your own computer; is acceptable if you run MacOS and just painful
if you're stuck on Windows[fn:: This is part opinion and part fact. There are ways to use Windows to
communicate with Unix machines that are not painful and in many ways the
situation is improving. But the statement is nevertheless pretty much true
and if you are going to spend some time doing informatics you might as well
get rid of Windows as soon as you can.].

* Basic orientation in the command line 

The command line appears as a window/terminal similar to
Fig. [[fig:terminal]]:

#+CAPTION: Command line window
#+ATTR_LaTeX: :width 14cm :float figure
#+NAME: fig:terminal
[[file:Terminal.png]]

The first line starts with your user name, followed by an =@= and then
the name of the computer you are working on[fn:: The beginning of the command line is referred to as the 'prompt' and
like many things, it can be changed by 
changing an environment variable (in this case the =PS1= variable).]. 
The line usually ends with a
=$= or =>= - after this sign you can enter your commands.

The Unix cheat sheet (see at the end of this file) provides an
overview of the core commands to navigate and operate in the Unix
command line. Most commands allow you to adjust their behaviour with a
variety of so-called options, flags or switches. Most of the commands, for
example, display help information if you use them with the =--help=
flag.

For example, if you type =ls --help= [fn:: Complete the command by pressing the =Enter= key (also called the 
return key and often denoted by down and left arrow).
], you'll get an overview of the
common usage of the command =ls= and of the flags that can change the
behaviour of this command.  The =--help= option doesn't provide much
help for the =ssh= command. In such cases you can try the =man=
command. It opens the manual page of the specified tool. For example,
try =man ssh=. If you want to leave the manual page, just hit =q=.
To search within the =man= program, simply type =/= followed by your search
term and hit enter. For example if you want to find something about colour
just type =/color= and hit enter[fn:: Note that in most cases American spelling is used; hence no u in a lot
of words and lots of z's.
]. For more details try =man man=, and if you've forgotten what command to use
you can try =man -k key_word=, where you substitute a suitable keyword related
to what you are trying to do; eg. if you wish to copy a file, =man -k copy=.
Before we will work on some sequencing data, let's have a look
at the commands that allow you to change directories and how to get an
overview of files that were saved in these directories.

** Directory navigation
Navigating through your directories[fn:: Directories are what you might call folders. It's probably best to
think of the file system as a hierarchical way of organising your files on the
computer. Think of it as a tree with the branches representing directories
and leaves representing files (although in a file system, leaves can also
grow directly from the trunk or main branches).] is a big hurdle if you are new to
the command line and are used to 'clicking' your way in and out of folders. To
understand how to move in and out of, and inspect the contents of folders (directories on Unix/Linux)
is an essential step to analyse your data on the command line.

*** Conventional directory layout

# XX Use http://brajeshwar.com/2008/filesystem-file-organization-in-linux/ as an orientation

#+begin_quote
On a UNIX system, everything is a file; if something is not a file, it is a process.
#+end_quote

This is a simplification but it is mostly true. A directory on a Unix
system is just a file that contains names of other files. Also
programs, images and documents are all files. These files are
hierarchically ordered in a conventional tree-like structure (see
Fig. [[fig:linuxfiletree]])


#+CAPTION: Conventional file tree structure on a UNIX system from [[http://linuxconfig.org/filesystem-basics][linuxconfig.org]]
#+ATTR_LaTeX: :width 12cm :float figure
#+name: fig:linuxfiletree
[[file:linuxfiletree.jpg]]


The root (represented as =/=) is the top-most level of this hierarchy.
When you connect to a Unix computer, you are automatically located in
your user home directory (=/home/username/=) and this is the only one
you have write access rights to in this course. Many of the programs and
scripts that you will use in this tutorial are located in the =/usr/=
directory, generally in =/usr/local/bin/=. 

Applications that are located in =/usr/local/bin/= can usually be run by any
user by simply typing the name of the application since this directory is automatically specified in the
=PATH= environment variable of all users. The =PATH= variable is simply a
variable that specifies the directories where the shell[fn:: The environment that
you use to interact with the computer is referred to as the /shell/. What you see when you
log into a Mac or Windows computer is referred to as a graphical shell. In this course you will
be using the Bash shell, which is one of the command line interfaces available on Unix systems] 
will look for files that can be executed.
You will meet this =PATH= variable again when you learn more about
running programs.

*** What files are present in the current directory?
    After you have logged in to the server your working directory will
    be set to your home directory. This is almost always:

    - /home/user_name

    To see what files and subdirectories are present in your home directory
    you can
    use the command =ls= (just type =ls= and hit enter). The tool =ls= comes with many
    options that refine the way that the results are shown; you get an
    overview of these options with:
  
 #+begin_src sh
 ls --help
 #+end_src

 The combination of options that I use most frequently are

 #+begin_src sh
 ls -lhcrta
 #+end_src

 The option
 - =-l= provides additional information to the file or folder name
	- file permissions
	- user and group owners of the file
	- size
	- date of modification
 - =-h= prints the file sizes in human readable format, like 100K instead of 102400
 - =-c= sort by last modification of file status information
 - =-r= reverse order while sorting (so that the newest files are the last that are printed)
 - =-t= sort by modification time, newest first 
 - =-a= prints also the hidden files (starting with a dot '.').

If you are not paying attention you may sometimes mis-type =ls= as =sl=. For =ls= this
is not a problem (try it!), but mistyping other commands can cause big problems, so
you do need to take some care (esp. with =rm=).

*** Moving in and out of directories with =cd=
 =cd= stands for 'change directory'. with this command you can navigate
 in and out of your directories. To see what your present working
 directory[fn:: You can think of your working directory as the location of the program
you are currently running. When you log in to a computer you access that computer through a /shell/,
which provides an interactive interface. The shell is just a program like any other, but it allows
you to start other programs through it. When you start other programs from the shell, these will inherit
the /working directory/ from the parent shell. The most common command line shell these days is =bash=
and this is what we will be using.] is, simply type =pwd= (for 'print working directory') and
 hit enter:

 #+begin_src sh
 pwd
 #+end_src

 The response in my case is:

 #+begin_src sh
 /home/alj/
 #+end_src

 When you want to 'move' to a different directory, the TAB key comes in
 handy as it auto-completes the possible sub-directories you can 'move'
 to. For example, when you type =cd= and hit the TAB key twice, you get an
 overview of all possible sub-directories. For example,

 #+begin_src console
 alj@inspiron:~$ cd 
 .adobe/
 Adobe/
 .cabal/
 .cache/
 .compiz/
 .config/
 --More--
 #+end_src

 Hit ENTER to see more sub-directories in your shell or 'n' to leave the
 list of sub-directories.

 If you know that your target sub-directory starts with the letters
 'Do', you can type these after the =cd= command and then hit TAB twice
 (once is enough if there is only one sub-directory that starts with the
 letters 'Do'):

 #+begin_src console
 alj@inspiron:~$ cd Do
 Documents/ Downloads/
 #+end_src

 I, for example, have two directories starting with 'Do', =Documents=
 and =Downloads=. So, TAB completion helps when moving into
 sub-directories, but how to get out of them again? With

 #+begin_src console
 alj@inspiron:~$ cd ..
 #+end_src

 you move one level up in your hierarchical directory structure.  If
 you want to go to your home directory from wherever you are, use

 #+begin_src console
 alj@inspiron:~$ cd ~
 #+end_src

 or just
 
 #+begin_src console
 alj@inspiron:~$ cd
 #+end_src

 You can arbitrarily concatenate file paths; to go up two levels of the file
 hierarchy and then descend into some subdirectory (eg, go from =~/Downloads/blast/=
 to =~/Documents/hts2017/= simply do:

 #+begin_src console
 alj@inspiron:~$ cd ../../Documents/hts2017
 #+end_src

*** Tip
If there are empty spaces in your filepath, you need to precede them
with a backslash (=\=) in order to navigate to them, like in 

#+begin_src sh
/home/my\ directory/
#+end_src

or use quotation marks

#+begin_src sh
cd "/home/my directory"
#+end_src

In general it is a good idea to avoid using file and directory names
that contain spaces. Many of the utilities that are used in bioinformatics
make use of =bash= scripts and these will not always handle spaces
in file names correctly. Instead of =My Documents=[fn:: Isn't that just an awful
directory name?], use =My_Documents=, or even =myDocuments=[fn:: These are referred
to as snake and camel case respectively for obvious reasons.]

*** Have a look at the directory structure
The command line tool =tree= prints the hierarchical structure of your
files and directories (recursing into all sub-directories) to the screen.

 To discriminate files from folders via colors, use the =-C= option

 #+begin_src sh
 tree -C
 #+end_src

 To show only directories, use the =-d= option

 #+begin_src sh
 tree -d
 #+end_src

 

Try also the following command:

 #+begin_src sh
 tree -sh
 #+end_src

Here, 
- =-s= provides the file and directory sizes
- =-h= prints the sizes in a human readable format

*** Tip
In addition to the TAB-key, that provides auto-completion of commands or
filenames, the UP- and DOWN-arrow keys on your keyboard can save you
some time. These buttons allow you to navigate through the history of
commands that you have entered previously. If you are used to typing then
instead of hitting the arrow keys you can type =C-p= (pressing the =p= with the
=Ctrl= key depressed) and =C-n= respectively for up (previous) and down (next).
You can also search your command history by using =C-r= (reverse search) and typing
part of the command that you are trying to recall; =C-a=, and =C-e= places the
cursor at the beginning and end respectively of the current command. 
These shortcuts may not sound like they are that useful, but they can speed up
your work considerably. Try them out!

*** Create, move and remove files and directories
New directories can be created with

#+begin_src sh
mkdir directoryname
#+end_src
Here, =directoryname= is the name of the directory you want to create.

To create a new empty file, use the command =touch=:

#+begin_src sh
touch filename
#+end_src

You can move or rename[fn:: Moving and renaming are logically the same procedure if you 
consider the full name of a file to include its location.] files with the command =mv=. For example:

#+begin_src sh
mv file1 file2
mv file1 ../file1
#+end_src

The first command renames file1 to file2. The second command moves
file1 one folder up[fn:: In unix, the =..= notation indicates the containing folder
(i.e. one up in the hierarchy).
].

If you don't want to move but copy a file, use the command =cp=.

#+begin_src sh
cp file1 file2
#+end_src

Instead of renaming file1 to file2, as the =mv= command does, the =cp=
command keeps file1 and creates a new file2 with the same content.

The most dangerous command that you will learn today is =rm=, which stands
for remove. If you remove a file with this command, it is gone and you
can not retrieve it. But if this is what you want, you can remove, for
example, file2 that we created above with the following command:


#+begin_src sh
rm file2
#+end_src

To remove an entire directory, use =rm= with the =-r= flag, like:

#+begin_src sh
rm -r directoryname
#+end_src

*** Tip
To get an overview of all the commands that you have used before, just
type


#+begin_src sh
history
#+end_src

and hit ENTER.

** Data transfer between computers
Before you can work on a remote server with your own data, you first
need to know how to transfer them.  One of the best
platform-independent GUI programs that allows you to up- and download
files is FileZilla (Download and Documentation:
https://filezilla-project.org/). In the following section I want to
introduce the command line tools =rsync= and =sftp/lftp=, that allow
you to transfer and synchronize files.
*** rsync


 =rsync= stands for "remote sync". This powerful tool has plenty of
 options.  Here is the most basic syntax to transfer files from a
 /source/ (SRC) location to a /destination/ (DEST) with =rsync=. (Text
 in square brackets denotes optional arguments, in this case optional
 options!)

 #+begin_src sh
 rsync [OPTIONS] SRC DEST
 #+end_src 

 SRC and DEST can either be files or folders. For example, to
 transfer the file 'file.txt' from your local home folder to a remote
 server, you can type:

 #+begin_src sh
 rsync --progress /home/user/directory/file.txt user@host://home/user/
 #+end_src 

 Here, you need to change =/home/user/directory/= to your own filepath and
 =file.txt= to your own filename. In '=user@host=', =user=
 represents your username on the remote server and =host= the IP
 address of the remote server.  The =--progress= option will indicate
 the progress of the file transfer - which is useful when transferring
 big files.

 If you want to transfer files from the remote server to your
 local computer, just swap the source and destination path
 specifications:

 #+begin_src sh
 rsync --progress  user@host://home/user/file.txt /home/user/directory/
 #+end_src

 If you want to transfer all files that are located in your local
 folder =/home/user/directory/=, you can use the following command

 #+begin_src sh
 rsync -avz --progress /home/user/directory/ user@host://home/user/
 #+end_src 

 Here,
 - =-a= will transfer the files in 'archive mode' (which combines
   several options, including recursing into directories)
 - =-z= will compress the files during the transfer
 - =-v= is a common option to increase the verbosity[fn::The amount of information
   that the program will print to the terminal.] of the output.

 Note the trailing slash after the source directory:
 =/home/user/directory/=. If you do not use this trailing slash, like
 =/home/user/directory=, then =rsync= will create a folder with the
 name =directory= at the destination and copy all files from the source
 folder into it.


 
*** sftp/lftp
rsync is a wonderful tool, but its power makes it complex and it can be
difficult to remember how to do even simple things (try =man rsync= if
you don't believe me!). When using rsync you also need to know and
remember where the files and directories that you wish to synchronise
are located. My preference is for using
programs similar to the old ftp command line client (which even Windows has). 
These provide an
environment very similar to the normal Unix shell, where you change
directory using =cd=, list the files using =ls=, find out where you are
using =pwd= and so on. However, the ftp protocol is inherently insecure;
it may not matter that the data is transmitted without encryption, but
you should be concerned about sending your password in plain text
across the ethernet. Not good. Hence, these days we use the sftp (secure
file transfer protocol) instead. On Mac and Unix systems you will
essentially always have the sftp command line client installed. On
Windows, well, you can use Putty or other third party tools. On Linux
systems you may also have the lftp command line client installed. Its
usage is almost identical to the usual sftp and ftp clients but it comes
with extended functionality that allows you for example to mirror (i.e.
synchronise directories) between the remote and local computers.

To use the sftp program, simply type:[fn:: On Windows you can use the PSFTP.EXE program
that comes as part of Putty. If you double click the icon, you will be
presented with a small terminal window. Follow the instructions written
at the top to proceed.]

#+begin_src sh
sftp hostname
#+end_src

into your terminal. The hostname may need to be specified as the IP
address (a load of numbers) or can be a simple name depending on your
setup and which computer you are trying to access. After the connection is made you will be asked for your password.
The sftp program assumes that you will be using the same username as you
are using on the local computer. If this is not the case you can specify
your username by:

#+begin_src sh
sftp username@hostname
#+end_src

After having successfully logged in to the remote computer you can move
around the directories as if you were logged in over a shell session
(i.e. using =ls=, =cd= and so on). If you wish to change the directory
on the local machine, simply use the =lcd= command. You can also run
commands in your local shell by prefixing these with an !, eg. =!ls= or
=!pwd=. You can create directories on the remote computer with =mkdir=,
and on the local machine with =!mkdir=. If you are using Windows, you will
obviously have to use the DOS equivalents of =ls=, =pwd= and =mkdir=[fn::
That is instead of typing =!ls=, =!pwd=, =!mkdir= you use =!dir=, =!cd= (without any directory)
and =!md= respectively. ].

To transfer files from the remote to the local computer use =get fname= (where
fname is the name of the file you wish to transfer). You can use globbing (*)
to expand the file set, eg. =get *.fa= for all files ending in '.fa'.  (For
this you may need to use =mget *.fa= on some implementations). Similarly you
can upload files using =put=.

As mentioned lftp is almost identical in its operation. However, when
starting the program you need to specify that you wish to use the sftp
protocol as it defaults to the standard ftp protocol (with an anonymous
user). Hence use something like:

#+begin_src sh
lftp sftp://username@hostname
#+end_src

lftp also allows you to mirror whole directory structures using the
=mirror= command which can save you a lot of time. Finally, when I
started using lftp, the standard ftp and sftp clients did not provide
tab completion, and this was a big advantage of lftp at that time. These
days most if not all of the clients provide this functionality, so it is
not quite as big a deal as it was in the long past. But lftp is hard to beat
for anonymous ftp (used to download data from public ftp repositories).

Ok, that's all we need to know to get the sequencing data from last
week to the remote computer. As we need the data in the following
tutorials, it is best if you upload them now.

*** Tip

If you want to transfer in one go, all files that have some common
patterns in their name you can use the asterisk =*=, which
stands for 'any character'. The =*= is one of the most commonly used
wildcard symbols that stands for a continuous string of characters. To
specify a set of filenames with wildcard characters is also referred
to as /globbing/.

For example, if you want to transfer all
fasta files at once, you can use

#+begin_src sh
rsync -avz --progress /home/user/directory/*fasta user@host://home/user/
#+end_src  
This means that any characters can precede the =fasta= file ending.



If you want to transfer all files that belong to a certain population
and are, for example, marked with 'Pop1' in the file name, you can use:

#+begin_src sh
rsync -avz --progress /home/user/directory/*Pop1* user@host://home/user/
#+end_src  
This means that any characters can precede or follow the =Pop1=
character in the file name.

* Running programs (and the PATH variable)
** From the (command line) shell
When using the shell you normally run a program by simply typing the
program name and any required arguments. But how does the shell know
what program to run and where to find it? On a typical Unix/Linux
system executable files (i.e. programs) can be found in a range of
standard locations (eg. =/bin/, /sbin/, /usr/bin/, ~/bin/=) as well as
anywhere a user puts them. Normally when you run a program by simply
typing its name, the shell will look for an executable file of that name
in a list of directories specified by the =$PATH= environment variable.
The first matching program is then run.

In practice the shell may keep the locations of executable files in
a cache in order to speed up the process
(remember that reading from disk is slow). In this case you may find
that the old version of a program found in =/usr/bin= is run instead of the 
new version installed in =~/bin/= even though
=~/bin/= is ahead of =/usr/bin/= in the =$PATH=. To fix this, you need to:

#+begin_src sh
hash -r
#+end_src

which will reset the internal cache and re-search the PATH.

The user can also directly specify the location (path) of the
executable; this is necessary if the program you wish to run is not
present in any directory specified by the =$PATH= variable, or if
multiple programs of the same name are present and you want to run one
of the later matches:

#+begin_src sh
/usr/local/bin/pg_ctl start
#+end_src

to start a version of the Postgresql database installed in
/usr/local/bin specifically.

You can also specify a path that is relative to your current location.
If for example your current working directory is
=~/Documents/testPrograms/= and you wish to run a locally installed
version of gcc (gnu C compiler) found in =~/bin/=[fn:: The =~= (tilde) character is used as shorthand for your home
directory.]:

#+begin_src sh
../../bin/gcc -o test main.c
#+end_src


(Remembering that ../ takes you up one level in the directory
structure). To do the same you could also make sure that the =$PATH=
contains ~/bin before other potential locations of gcc.

To check the current value of your =$PATH=, simply use the =echo= command:

#+begin_src sh
echo $PATH
#+end_src

To learn how to extend your own PATH variable have a look in the hidden
.basrhc or .bash_profile file in your home directory. It usually gives a
few examples. Failing that have a look at Google.

Finally if you've written a small script or installed a program in your
current working directory you can run that by typing =./scriptname=. There
is nothing special about that, it is merely how you represent the
relative path to your current working directory.[fn:: Previously you learnt that =../= represents the containing directory
(one level up); the =./= is simply shorthand for the current working directory. 
]

** From a shell script
You may have noticed that the commands to run sequence analysis programs can
be quite long and complex. This is because the program allows you to specify
many different options directly when invoking the program rather than by
interactively asking you through some sort of interface. This is convenient,
as it allows you to do something else as soon as you have invoked the
program. However, it can be difficult to remember the exact details of how to
run something that you do not use every day. Fortunately you do not need to
remember this yourself; there is a better way: instead of running the program
from the command line you create a small text file that contains the commands
that you wish to run, and then you ask the shell (i.e. the command line
interface) to run the commands contained within your text file. Since your
file can also contain comments this allows you to add explanations as to what
the command does and why you chose to run it that way.

For example we could just type the following into the terminal to map
sequences in =seqData.fastq= to the genome provided in
=~/apps/STAR/STAR/genomeDir/Zv10/unmasked/=
using the STAR program:

#+begin_src sh
STAR --outFilterMultimapNmax 5 \
--outFilterMismatchNoverLmax 0.05 --outFilterIntronMotifs RemoveNoncanonicalUnannotated \
--genomeDir ~/apps/STAR/STAR/genomeDir/Zv10/unmasked/ --readFilesIn seqData.fastq \
--runThreadN 6 --outSAMtype BAM SortedByCoordinate
#+end_src

But that is both difficult to remember and to type fully without
making any mistakes. It is much easier to create a small text file,
maybe called, =map_seq.sh= [fn:9] that contains the code with some
comments to explain what does what:

[fn:9] Shell scripts are normally named with a =.sh= extension; this
makes it easy to identify them. However, Unix doesn't care, and you
are free to name the scripts as you like.


#+begin_src sh

#!/bin/bash

## this command will use STAR to map the sequences in seqData.fastq to
## the unmasked version of the Zv10 (zebra fish) genome sequence

STAR --outFilterMultimapNmax 5 \
--outFilterMismatchNoverLmax 0.05 --outFilterIntronMotifs RemoveNoncanonicalUnannotated \
--genomeDir ~/apps/STAR/STAR/genomeDir/Zv10/unmasked/ --readFilesIn seqData.fastq \
--runThreadN 6 --outSAMtype BAM SortedByCoordinate

## --outFilterMismatchNoverLmax : the maximum proprotion of mismatches
## --outFilterIntronMotifs RemoveNoncanonicalUnannotated : don't report 
##   weird splice positions
#+end_src 

You can now run this script in two different ways. Either first make it
executable by changing its permissions: =chmod +x map_seq.sh= and then run it
from the directory where it exists, =./map_seq.sh=. Alternatively you can
invoke the bash shell on the script by typing =bash map_seq.sh= and hitting
enter. In the latter case you do not need the first line of the script to be
=#!/bin/bash=, but it is usually included for completeness. Note that comments
in shell scripts are preceded by the =#= character. Anything that follows
this on the same line is considered as a comment and will not be executed by
the shell. 

You may also have noticed the backslash (=\=) characters at the end of
many of the lines. The backslash is usually used as an escape character which
means, 'ignore the special meaning of the following character'. In this case the
character following the backslash is the newline (often represented as =\n=)
character which is usually interpreted by the shell to mean that the complete
command has been entered. Here we use it to be able to split the command across
several lines of text to make it more readable. Note that the newline character
(entered by pressing =Return= / =Enter=) must follow immediately after the
backslash.

Writing a script file to run a single command like this may not look like it
helps you very much, but there are a number of advantages over simply writing
the command directly:
- You can spend some time to proof-read the command making sure you don't
  have any stupid mistakes in it.
- You have a record of how you ran the program. This is actually _very_
  useful.
- You can look at this file next time you have something to map and remind
  you of how you use the program.

However, the real beauty of making a shell script is that the shell provides
a simple programming environment and this means that you can automate the
processing of large numbers of files. For example if I wish to run the above
command in a set of sub-directories whose names all start with =RZY-3= I can
use the following script:

#+begin_src sh
#!/bin/bash

dirs=RZY-3*

for d in $dirs
do
    echo "entering directory: $d"
    echo 
    cd $d
    f=$d.fastq
    echo "Processing: $f $(date +'%b %D %H:%M:%S')" 

##    STAR --outSAMstrandField intronMotif --outFilterMultimapNmax 5 \
##    we have directional libraries and should not use the 
##    outSAMstrandField intronMotif function
    STAR --outFilterMultimapNmax 5 \
         --outFilterMismatchNoverLmax 0.05 \
         --outFilterIntronMotifs RemoveNoncanonicalUnannotated \
	 --genomeDir ~/apps/STAR/STAR/genomeDir/Zv10/unmasked/ \
         --readFilesIn $f --runThreadN 6 \
	 --outSAMtype BAM SortedByCoordinate

    echo "      Done: $f $(date +'%b %D %H:%M:%S')" 
    cd ..
done
#+end_src 

Here we first use a wild card notation =dirs=RZY-3*= to create a list of
directory names. We then use a loop (=for d in $dirs=) to go through each
directory in turn. For each directory we first use =cd= to change our current
working directory, then assign the the file name to =$f= (=f=$d.fastq=). In this case
the filenames all have the same prefix as the directory name, so we can
simply concatenate the dirname and the =.fastq= suffix together) to obtain the =$f=
variable which we then use to create the command to run the program. After =STAR= returns
(i.e. it has finished running) we go back to the starting directory (=cd ..=)
and go to the next directory.

When we define a variable we simply write the name of it without any
decoration; (eg. =f=$d.fastq= to define the =$f= variable). However, when we
use the variable we have to decorate it with the =$= sign.

We use =echo= throughout the script to print
information about the process of the script. This ouput, in addition to that
printed by the STAR program can be redirected to a file (a log) so that we
can leave the process to run and then come back and see if there were any
errors encountered during the processing. To run the script, first =chmod= it
to an executable and then run it:

#+begin_src sh
chmod +x map_seq.sh
./map_seq.sh > map.log &
#+end_src

This will run the commands in the shell script and redirect =STDOUT= to the
file map.log. The =&= at the end of the line returns control back to the
terminal so that you can do other things rather than just waiting for the
process to complete.
If you are using a remote computer you should probably do :

#+begin_src sh
nohup ./map_seq.sh > map.log &
#+end_src

as that will now allow you to log off, and do whatever you like. As long the
server doesn't crash (or an administrator stops your process) the process
will complete without any input from you.

If you wish to follow the process of the mapping, you can use the
=tail= program to view the output of the shell script. If you invoke
it with the =-f= option it will follow the file you specify, printing
the new lines of it as it is written to:

#+begin_src sh
tail -f map.log
#+end_src

To stop following the file you will need to hit =Ctrl-C= (i.e. the
control and C keys simultaneously).

Note that the above example is not a particularly good script as it does
not bother to check if the names obtained by globbing (=dirs=RZY-3*=) are actually
directories, nor checks if the sequence files exist. As I wrote this script
for a specific situation where I knew[fn:: The idea of knowing what actually exists
within a complex directory structure is somehow not a very reasonable one as it is
difficult to check manually and be confident of not having missed something. Equally
it is difficult to check automatically though a small script as it is easy to have either
implementation (eg. typos) or logic errors.] the directory structure prior to writing
the script (it having been created by another script). However, it is bad to make
assumptions and when writing any script or program you should check the input to make
sure it conforms to your expectations. In this case we can use =if then else=
conditional statements to make sure the directories and files exist:

#+begin_src sh
for d in $dirs
do
    if [-d $d]
    then
        echo "$d is a directory"
        cd $d
        f=$d.fastq
        if [-e $f]
        then
            echo "$f exists, we can do something with it"
        else
            echo "ERROR $f does not exist in $d"
        fi
        cd ..
    else 
        echo "$d is not a directory"
    fi
done
#+end_src

Note that using nested =if=[fn:: if statements within if statements] statements
make it difficult to read the code and work out what is going on. To make it
easier to read we normally use indentation to indicate the different levels
of conditional, but it is still easy to make mistakes. One of the advantages of
using a specialised text editor is that it will automatically create this
indentation for you: and when you do something stupid it often results in
obviously wrong indentation. This is very useful for catching silly mistakes.

** File permissions

In the above section we included a brief mention of the =chmod= program. This
is used to change the permissions of a file, but we did not explain what this
means. In Unix based systems, every file is associated with a set of permissions
that tell the shell who can do what with a file. A file can be any
combination of:

- executable :: the file is a program and can be run as a program
- writeable :: the file can be modified (i.e. changed or deleted)
- readable :: the file can be read

In addition every file is considered to be owned by one of the users
of the computer and to be associated with a group of users.
For each file three independent permission combinations are set:

- owner :: permissions that apply to the owner of the file
- group :: permissions that apply to any members of the group
     that the file is associated with
- world :: permissions that apply to any user that is able to
     see the file (this depends on the permissions of the containing
     directory)

To see the permissions of the files in given directory use =ls -l=:

#+begin_src console
> ls -l
-rwxrwxr-x 1 lmj lmj        666 feb.   9  2016 countVariants.pl
-rwxrwxr-x 1 lmj lmj      99063 feb.  12  2016 readSam
-rw-rw-r-- 1 lmj lmj 2373563641 feb.  11  2016 variants
#+end_src

The permissions are given for each file as a triplet of character triplets:
=rwx= indicates read, write and execute, =r-x= read and execute, =r--= read
only and so on. Hence the first file (countVariants.pl) has full permissions
for both the owner and the group[fn:: You can see who owns the file and which
group it belongs to in columns 3 and 4 of the output of 'ls -l'. Here the
names of the owner and group are the same as there is both a group and a user
called 'lmj' on this system.], but can only read and executed by other
users. In contrasts, the 'variants' file is a data file that can be read and
written by the owner and group members, but only read by other users.

The program =chmod= is used to change the permissions. Ownership and group
association can be changed with the =chown= and =chgrp= commands. To make a
file executable we can use the shorthand =+x= as described above. But to
specify the complete set of permissions we use a single digit for each set of
permissions. This single digit is made up of the bitwise =OR= combination of 4
(read), 2 (write) and 1 (execute). If you don't understand what this means you
can simply add up the values to get the final digit:

- 7 :: 1 + 2 + 4 = execute, write and read
- 6 :: 2 + 4 = write and read 
- 5 :: 1 + 4 = execute and read
- 4 :: 4 = read
- 3 :: 1 + 2 = execute and write
- 2 :: 2 = write
- 1 :: 1 = execute

Hence =chmod 700= sets full permissions to the owner and no permissions for
other users, whereas =chmod 755= sets read, write, execute to the owner and
read and execute to other users. Note that it is better if you can get to
understand how bitwise flags are used as they frequently pop up in many
places. Thinking of them as additive kind of works, but it doesn't expose you
the full beauty of the concept.

** Writing a shell script
To write a shell script you will need to use some sort of editor. There are
very many to chose from; for experienced Unix / Linux users the two most
commonly used editors are probably =emacs= and =vi= (these days perhaps
=vim=). These editors are very powerful tools for writing computer code, but
can take a certain amount of time to learn. For this course we recommend you
to try the =nano= editor. To edit or create a new file with =nano= simply
type =nano filename= and start typing. Commands to save, exit, cut, paste,
etc. are indicated at the bottom of the screen. =^= is shorthand for the
=Ctrl= key.

But if you are likely to end up doing a lot of informatics work, then it is
worthwhile to learn to use a more advanced editor. Which one is a topic of
heated debate since time immemorial, but regardless of which editor it is
better to learn one that can be used from a terminal window with no grahical
interface as you'll always be able to make use of that.
#+CAPTION: The Nano editor.
#+ATTR_LatTeX: :width 12cm :float figure
#+name: fig:nano
file:nanoShell.png

* Retrieving basic information from common NGS files
 
Now that we know how the commandline works, how we can change
directories and transfer files, it's time to look at NGS data output
and to learn how to open and summarize information from such files -
like, for example, the number of sequences in a fasta file.

The folder =/home/hts2017/PracticeFiles= contains the following files:
- HTS.fasta and HTS2.fasta, fasta files with sequence identifiers and sequences
- HTS.fastq, a file with sequences and associated base qualities
- HTS.sam, an alignment file

** Look at the content of a file and search for patterns 
The tool =less=[fn:: =less= is very similar to the more basic program =more=. Its
name is a bit of a joke on 'less is more'. Habits die hard, and at
least one of the authors of this document has =more= hardcoded into
his fingers.] can be used to display the content of text
files one line or page after the other. Since it doesn't read the
entire content of a file at once, it is very useful for looking into
large files.


Let's have a look at a fastq file with the command:

#+begin_src sh
cd /home/hts2017/PracticeFiles
less HTS.fastq
#+end_src

Once you have opened a fasta file with =less= (or =more=) ...

... you can search for patterns, like the nucleotide sequence 'GCTC', with =/=, like

#+begin_src sh
/GCTC
#+end_src

hitting =n= repeats this search on the remainder of the file.

To show only those lines in the file that match the nucleotide
sequence 'GCTC', type this sequence after the =&= sign:

#+begin_src sh
&GCTC
#+end_src
 
To go to the last line of the file, just type =G=, to go to the first
line, type =g=. To close the file again, hit =q=.


The =less= command has more options than this. You get an overview of
these with the =--help= flag:

#+begin_src sh
less --help
#+end_src


The =head= command, followed by the name of a text file, prints by
default the first 10 lines/rows of the file to the terminal.  The =-n=
option allows to specify the number of rows that will be
printed. For example, to extract the first sequence-id along with the
nucleotide sequence from HTS.fasta, you can select the first two lines
with:

#+begin_src sh
head -n 2 HTS.fasta
#+end_src

When the line number =K= is preceded with =-=, then all but the last =K=
lines are printed. For example, the command to print all but the last
ten lines from a HTS.fasta[fn:: But you might not want to do this if the file is
very large...] is:

#+begin_src sh
head -n -10 HTS.fasta
#+end_src

The =tail= command, in contrast, prints by default the last 10 lines
of a file to the terminal. Also here you can select the number of
lines with the =-n= option. When the line number =K= is preceded by a
=+=, then all but the first =K= lines are printed.  For example, to
exclude the first two lines from HTS.fasta

#+begin_src sh
tail -n +2 HTS.fasta
#+end_src


To extract specific lines from a file, the tool =sed= can help you. To
print all lines between line 234 and 236 from HTS.fasta, for example, use:

#+begin_src sh
sed -n '234,236p'
#+end_src


** Counting words, lines, and characters with 'wc' and searching for patterns with 'grep'
If you want to get a rapid overview of the number of lines in a file,
the =wc= command (word count) is the right tool. In output-files where
every line represents a sequence, for example, =wc -l= is all you need to count the
number of sequences.

#+begin_src sh
wc -l File.txt
#+end_src

The =-l= option specifies that you want to count the number of
lines. The =-m= and =-w= options further allow you to count the number
of characters or words.


To count the number of sequences in a fasta file, you have to limit
the lines that are counted to those starting with a ">" sign
because ">" precedes every sequence identifier:

#+name: Structure of fasta file
#+begin_src sh
>SEQ1_ID
GGATTCATAGAAACCATAGATACATAGATACATAGATTAGGGACAGATAATAG
>SEQ2_ID
GATTTGGGGTTCAAATTAGTATCGATCAAATAGTAAATCCATTTGTTCAACTC
>SEQ3_ID
AGATACAGAGAGACAAGACATAGACAGATAACAGAATAGAGATAGAGGAGAGG
#+end_src

=grep= allows you to extract lines that contain specific
characters, like ">". 


If you type

#+begin_src sh linenos
grep ">" HTS.fasta
#+end_src

All lines in HTS.fasta that contain the ">" character are printed to
the screen. You can stop the flow of output by pressing Ctrl+C. If you
don't want to write these lines to the screen but want to count them,
the =|= symbol provides a 'pipe' to pass the output from the =grep=
command to the =wc= command. So, to count the number of
sequences in HTS.fasta, you can use the following command:

#+begin_src sh
grep ">" HTS.fasta | wc -l
#+end_src

Here a recap on what the commands mean: =grep= is used to search for
=>= signs in the fasta file. All sequence ids start with this
character. Instead of printing all these lines to the terminal, we
re-direct it to the =wc= command with the pipe symbol =|=. Using the
=-l= option, =wc= counts all the lines. Here, =wc= doesn't need an
input file as it reads from the output of =grep=[fn:: When a program prints it's output to the terminal (i.e. the
screen) it's normally printing to a stream referred to as =STDOUT=
(standard out). When we use the pipe symbol (=|=) we can redirect this
output to programs than can read from the =STDIN= stream. We can also
use the =>= to redirect the output to files. Note that output printed
to the =STDERR= stream will also be printed to the terminal, but will
not be redirected using =|= or =>= (though you can use =2>= to
redirect =STDERR=).]. If you have a look at =man grep= you can find
an alternative way of counting the lines, as grep provides an optional
argument (=-c=) that only outputs the number of lines that match, but
there are many other situations where piping the output to another program
is the most efficient way to solve your problem. Note that you can
also refine the search by writing, =grep "^>" file.fa=. Here the =^= modifier
specifies that the =>= character must be the first character the line to match.


Your turn. What command would you use to count the number of sequences
in a fastq file?
# Search for the instrument name that follows the @ sign and then pipe it to |
# Or count all lines and divide them by 4 wc -l ES24_sub.fq | awk '{print $1/4}'; 


If you are in doubt what quality encoding your fastq file has, =grep=
can help you. Have a look at Fig. [[Fig:QC]]. If you find one of the ASCII
characters 33 (character'!') to 58 (character ':'), you can be sure
that the quality encoding is Phred+33. 


#+CAPTION: Quality score encodings
#+name: Fig:QC
#+ATTR_LaTeX: :width 14cm :float figure
[[file:Fastq.png]]


So, try if you find one of the Phred+33-specific quality characters in
HTS.fastq. For example:

#+begin_src sh
grep "!" HTS.fastq | wc -l
#+end_src



=grep= also allows you to search for the sequence of a specific
gene-id and identify the line of the hit in a fasta file, if you use
it with the =-n= flag. For example, if you want to know which line
in the HTS.fasta file holds the sequence with the gene-id
'gi|612475216|gb|AZHG01011862.1|', you can use:

#+begin_src sh
grep -n "gi|612475216|gb|AZHG01011862.1|" HTS.fasta
#+end_src

It is line 23724.

** INFO on regular expressions

=grep= stands for /global regular expression printer/ and is a
command-line utility for searching plain-text data for lines matching
a regular expression. With regular expressions you can match strings
that are not identical but follow a specified pattern.  We won't
go into further detail here, but you can read more about regular
expressions in [[http://www.scootersoftware.com/RegEx.html][A Tao of Regular Expressions]] and you can find a 
short introduction in the Perl section below. Also, [[http://www.cheatography.com/davechild/cheat-sheets/regular-expressions/][here]] you will find
a cheat sheet with essential regular expressions.

** Combine the content of files with 'cat' and '>'
The most common use of the =cat= command is to redirect the contents of
text files to other files or commands.

The following command, for example prints the content of HTS.fasta to the screen

#+begin_src sh
cat HTS.fasta
#+end_src

With the =>= and =>>= operators, you can print the content of files
not to the screen but to other files. This allows you to rapidly combine
two files, even huge ones. For example, in the following command
=HTS.fasta= and =HTS2.fasta= are combined to
=COMBINED.fasta=.

#+begin_src sh
cat HTS.fasta > COMBINED.fasta
cat HTS2.fasta >> COMBINED.fasta
#+end_src

The =>= operator redirects the output of the =cat HTS.fasta=
command (the content of =HTS.fasta=) to =COMBINED.fasta=. The
=>>= operator adds the output of the =cat HTS2.fasta= command to
the =COMBINED.fasta=. If we would use the =>= operator instead of
the =>>= operator in the second line, the content of
=COMBINED.fasta= file would be overwritten, not appended. So, the =>=
operator (over) writes content to a specified file while the =>>=
operator appends content to a specified file. If you use the =>>=
operator with the name of a file that doesn't exist it will act like
the =>= operator and create the file.

Note that you can achieve the same by:

#+begin_src sh
cat HST.fasta HTS2.fasta > COMBINED.fasta
#+end_src

but we wanted to show you the difference between =>= and =>>=.

** Counting filtered reads in SAM files with 'awk'
Later in the course we will encounter specific programs that can filter
SAM and VCF files. Here, I want to show you that we can also use basic
command line tools to filter such files.  The command line tool =awk=
can extract single columns or apply a filter on column values in
any file that is organized in columns - as SAM and VCF files
are. The =-F= option allows you to specify if your columns are
delimited by commas, spaces, tabs or any other character.

We learned this morning that SAM files (alignment files) are
 tab-delimited (=\t= and always contain the mapping quality in the
 fifth column (=$5=). Thus, to count mappings in a SAM file that
 have qualities > 20, we first strip off the header lines
 containing the =@= character  with =grep=:

#+begin_src sh
grep -v "^@" HTS.sam
#+end_src

Here, the =-v= option inverts our search (all lines including =@= at
the beginning of the line - specified by the =^= sign - are excluded).

The above command would print all non-header lines to the
screen. Instead, we want to pipe the output of this command to =awk=,
in order to extract only those reads with a mapping quality >20 and
then pipe this output to =wc= to count the lines:

#+begin_src sh
grep -v "^@" HTS.sam | awk -F "\t" '$5 > 20 {print $0}' | wc -l
#+end_src

Here, =$0= refers to the entire row, while =$5= refers to column 5 of
that row. =-F= just specifies the field separator, and
=\t= sets it to the TAB character. Since we pipe (using =|=) the output of =grep= to
=awk=, and then the ouput of =awk= to =wc= the lines are not printed to screen but directly
counted with the =wc= command. Only the output of =wc= gets printed to the screen.
* Running programs in the background with =nohup=
What if your data analysis on a remote server takes several hours,
days, or even weeks, to finish? No worries, you don't need to be
connected to the remote server while the data are being
analysed. Here, you will learn the tools that allow you to start
an analysis, disconnect from the server, and then look at the progress
or the results at a later time point.

The =nohup= tool allows you to run a process in the background; which
means that, while the analysis is running, you can do other tasks in
parallel or log off from the remote server.

Imagine the =nohup= tool as a bracket which encloses the command that
you want to run in the background:

#+begin_src sh
nohup ... &
#+end_src

Always, =nohup= precedes and =&= follows the command that you want to
run in the background (here shown as =...=). Let's say you want to run
the command =ls -lhcrt= (which lists all files and subdirectories in
your current directory) in the background.

#+begin_src sh
nohup ls -lhcrt &
#+end_src

When you hit ENTER, the terminal prints out some information:

#+begin_src sh
[1] 21118
nohup: ignoring input and appending output to 'nohup.out'
#+end_src

The number =21118= (which will differ in your case) in the first line
is the process-ID of your background-process. The second line informs you that
all 'results', that would be normally printed in the terminal window,
are now redirected to the file =nohup.out=. 

* Using the process-ID
If you have started a process that takes several hours
to finish, then you can use the process-ID to see if the process is
still running. For this, you can use the =ps= command with the =-p=
option, which reports the status of a process with a certain process
ID. To see the status of the process I have started above, I would
use:

#+begin_src sh
ps -p 21118
#+end_src

The output is

#+begin_src sh
PID TTY          TIME CMD
#+end_src

Since this is only the header line of the process specifications, the
process must have finished. 
Here:
- =PID= indicates the process-ID
- =TTY= indicates the controlling terminal
- =TIME= shows the time that the process is running already
- =CMD= shows the command name

If the process would still run, you would
get a line similar to:

#+begin_src sh
PID  TTY          TIME CMD
21118 ?        00:00:04 ls
#+end_src

The =top= tool provides an ongoing look at processor activity in real
time, similar to Figure [[fig:top]].


#+CAPTION: Screenshot of the =top= tool output
#+name: fig:top
#+ATTR_LaTeX: :width 10cm :float figure
[[file:top.png]]

At the top of the screen, it lists processes ordered by their CPU usage
system (with the most intensive on top). Besides other information, it shows which user is running
which process, as well as the process-ID. You can quit the program by
hitting =q=.

The process-ID also allows you to cancel the process before it
finishes. Cancelling processes comes in handy when you figure out
that you started them with the wrong parameters or input files and you want
to re-start with different settings. The =kill= command allows you
to cancel a specific process.

#+begin_src sh
kill 21118
#+end_src

This would cancel the process that we started before in the
background. If you can't remember the process-ID but want to cancel
all =ls= processes, then you could use the =pkill= command in the
following way:

#+begin_src sh
pkill ls
#+end_src

Compared to the =kill= command, the =pkill= command allows you to
specify the command-name instead of the process-ID of the running
process that you want to cancel.

If you don't have a record of the PID you can find out the id of processes being run by a specific user
by combining =ps= and =grep=:

#+begin_src sh
ps aux | grep user_name
#+end_src

where =user_name= is your own user name. That will list all processes started by
you (well using your id in any case). The =aux= option specifies all processes and
the manner in which these are printed out. If you read the man file (=man ps=) you
will see that there are ways in which you can get ps to only list processes started
by the current user (=ps -eu=) in a similar manner and that =ps aux= is BSD syntax.
So =grep= isn't really needed here, but I tend to like the way this formats the output.

* Redirecting output
By default, the =nohup= command redirects all information from the
terminal window to the =nohup.out= file. If the file exists already,
it will not be overwritten. All new information will be appended to
the end of the file. With the =>= operator, you can redirect the
output to a different file. For example, to redirect the output of the
=ls= command to the file =Directory-Listing.txt=, you can use the
command

#+begin_src sh
nohup ls -lhcrt > Directory-Listing.txt &
#+end_src

So, the redirection-operator (=>=) is followed by the name of the
target file and precedes the closing =&= operator of the =nohup=
command. If you want to save the output to a file in a different
directory, just specify the entire file-path that precedes your target
file, like:

#+begin_src sh
nohup ls -lhcrt > /home/alj/Documents/DirectoryListing.txt &
#+end_src

* Open and edit smaller files with 'nano'
=nano= allows to open and edit small text files from the command
line. It is not meant to open big files, like for example raw fastq
files. The name of the file you want to open has to follow the =nano=
command. For example,

#+begin_src sh
nano Testfile.txt 
#+end_src

Once you hit ENTER, =Testfile.txt= will be opened and you can scroll
through it, and compared to the tools we looked at before, you can
edit the content of the file by deleting and adding text. At the
bottom of the terminal window you see some shortcuts for certain
actions. For example =^O WriteOut= or =^X Exit=. The =^= indicates
that you need to press CTRL+O or CTRL+X. Just open a file and try it
out. 
   
* Installing programs

In your analyses you are likely to end up using a wide range of programs, and
you may find it difficult to get system administrators to install these for
you whenever the need arises. This isn't just because your administrators are
lazy and unhelpful: we sometimes have legitimate reasons for not simply
installing everything under the sun.[fn:: The biggest of which is namespace
pollution and version conflicts, but there are many other reasons as well;
disk space, however, isn't usually one.] Luckily, on unix systems it is
usually not difficult to install programs in your own home directory. This means
that it is easy to try out new methods and algorithms without bothering anyone
else.

** What is an installation?

You may have some previous experience of installing software on your own
computer.  On Windows and Mac machines this usually involves clicking some
executable file that runs an installation program or dragging some icons over
some other ones causing some magic to happen. What happens when you do this
depends on the program and what it actually comprise.

- In the simplest case, where the program consists of a single executable
  file, all the installer needs to do is to place (i.e. copy it) it in a location
  where the shell expects to find it so that it can be run in the usual manner.
  For command line shells this simply means placing it somewhere in the =PATH=.
- A simple program as described above may also come with documentation that
  can be found and read by the =man= program. In this case this documentation
  (usually a single file) will need to be placed where =man= expects to find
  it.
- In a slightly more complicated scenario, our single executable file may
  depend on functions provided by libraries (dynamically linked libraries on Windows,
  shared object files on linux). In this case the installer first needs to check
  if those libraries are present and accessible on the system. Then it copies
  files to the appropriate locations.
- Something that is referred to as a single program may in fact comprise many
  individual executables, which in turn rely on configuration options specified
  in specific files. In such cases, all of these files need to be put into a
  location where the executable can find the appropriate files. Sometimes this
  may achieved by modifying global configuration files or environment variables.

What is required during an installation depends to a large extent on the complexity
of the software being installed and the above is not an exhaustive list of what
can be done by installer scripts or programs. In addition to this on Linux systems
there are some additional distinctions:

- Software that is part of the distribution. Linux systems are normally provided
  as distributions that comprise many thousands of programs; normally when you install
  the system you chose a subset of these that are suitable for your own needs. The
  programs provided by the distribution and their requirements are usually described
  in some sort of database. Installing programs that are part of the distribution
  is usually very easy and can be done with a single command line as long as one
  knows the name of the package that's needed. The software management system is
  usually able to install all required dependancies, and this is by far the simplest way
  to install software on linux. However, root (i.e. admin) access is usually a requirement,
  and the bioinformatics programs that you want are not likely to be part of the
  distribution (or even if they are they may not be up to date).
- Software that is outside of the distribution. Here the distribution does not take
  responsibility for the installation and the software providers need to create
  the appropriate installation scripts. Thankfully there are some standard methods for
  doing this which will be described below.
- Software which is provided as source rather than as compiled binaries. These
  need to be compiled by the users. Again, this is usually not a problem and there
  is a kind of standard system for this.

Again, the above is a bit of a simplification and you may come across other variations
on the theme. But the general theme of any installation is:

1. Check dependancies
2. Compile (if necessary) the source code to binary executable files
3. Place files in appropriate locations
4. Occasionally, update some environment variables or configuration files

** Getting the program files
Usually you will find the program(s) that you wish to install through reading
about them in a web-browser which will also provide links that allow you to
download the file. These days, these links tend to be =http= or =https= links,
meaning that they make use of the /hyper-text transfer protocol/. This is what
you may know of as the /web/, and which you usually a web-browser to access.
However, if you wish to download the software to a remote server, you do not
usually wish to (and may not be able to) start up a web-browser to find the
file.[fn:: The first web-browsers were simple applications which did not provide
graphical interfaces; such browsers still exist and can be used over a simple ssh connection.
However, web-sites these days are often too complex to make sense of without a GUI and this
isn't actually that helpful.] Instead we have the =wget= application. If you know the
URL[fn:: Uniform Resource Locator] of the file you wish to download (you can get this by right-clicking on links and choosing 'copy link location')
then you can simply:

#+begin_src console
>wget https://github.com/samtools/samtools/releases/download/1.4/samtools-1.4.tar.bz2
#+end_src

Software is usually downloaded as a compressed archive of files. This will need to
decompressed and un-archived. How this is done varies a bit, but you can usually
work it out from the suffix of the downloaded files:

- f.zip :: =unzip f.zip= (not so common on Linux)
- f.tar.gz :: =tar zxvf f.tar.gz= (one of the most common formats)
- f.tar.bz2 :: =bunzip2 f.tar.bz2= followed by =tar xvf f.tar=

where 'f' simply indicates the file names without their suffixes. For more information
about the different programs use =man=!

The files you wish to download may also be present in =ftp= repositories; if you
know the URL, you can still use =wget=, but you can also the =ftp= and =lftp=
programs.

** configure, make, make install

The standard[fn:: There are probably lots of people who would argue against
this being the standard, and they may have a point; however, well behaved
applications frequently make use of this system.] way for installing out-of-tree
applications (i.e. not provided by the distribution) is to make use of the =autoconf=
package. We will not go into details as to how you use this to make the installer scripts,
but merely to how you use the end product to install. Installation using =autoconf= generated
scripts takes three steps:

- ./configure :: This runs a script called =configure= provided by the
     application writers. The =configure= script attempts to establish that
     all the dependancies of the application are met. If something is missing
     it will exit with an error telling you that you need to install
     something. If you do not have root access this means that you will have
     to install the dependancy in a non-standard location after which you will
     have to tell the =configure= script where to look for the dependancy by
     specifying the value of one of it's many optional arguments. The =configure=
     script creates a =Makefile= which is used by the next step of the process.
- make :: This runs the =make= program which reads the =Makefile= produced by
     the =configure= script and follows the rules therein to compile the
     program source code.[fn:: Usually anyway; in fact make can do pretty much
     anything, but usually this step is used to compile the code.]
- make install :: Again, this runs the =make= program, which looks in the
     Makefile for information as to what should be done to install the program.
     This usually involves copying files to suitable locations; but again, the
     =make= system is mighty and can do pretty much anything.

*** configure
The =configure= script is the most important part of the installation; it will
usually take a large number of optional arguments that allow you to fine-tune
how the installation is performed. To see what arguments the script takes:

#+begin_src console
> ./configure --help
`configure' configures bfast 0.7.0a to adapt to many kinds of systems.

Usage: ./configure [OPTION]... [VAR=VALUE]...

To assign environment variables (e.g., CC, CFLAGS...), specify them as
VAR=VALUE.  See below for descriptions of some of the useful variables.

Defaults for the options are specified in brackets.

Configuration:
  -h, --help              display this help and exit
      --help=short        display options specific to this package
      --help=recursive    display the short help of all the included packages
  -V, --version           display version information and exit
  -q, --quiet, --silent   do not print `checking...' messages
      --cache-file=FILE   cache test results in FILE [disabled]
  -C, --config-cache      alias for `--cache-file=config.cache'
  -n, --no-create         do not create output files
      --srcdir=DIR        find the sources in DIR [configure dir or `..']

Installation directories:
  --prefix=PREFIX         install architecture-independent files in PREFIX
                          [/usr/local]
  --exec-prefix=EPREFIX   install architecture-dependent files in EPREFIX
                          [PREFIX]

By default, `make install' will install all the files in
`/usr/local/bin', `/usr/local/lib' etc.  You can specify
an installation prefix other than `/usr/local' using `--prefix',
for instance `--prefix=$HOME'.
#+end_src

the above shows the start of the output of =./configure --help= for the =bfast= program. Almost always
you will be able to set the =--prefix= option. This is the directory prefix
denoting the directory tree into which the various components of the
application will be installed.  The default value is usually =/usr/local/=, which
is accessible by all users of the computer. However, unless you have root access
you will not be able to modify the files which are there. Hence to install
files as a normal user you will need to modify this value to a directory
that you have write access to. For example you could simply write:
=./configure --prefix=~/.local= which would install files in a hidden
directory called =.local= within your home directory. You would then
need to modify your =PATH= variable to make sure that it includes =~/.local/bin=
in order to run the programs directly from the command line.

The configure script may also allow you to set a large range of options dealing
with how the sources will be compiled. You usually don't need to worry
about this, but it is worthwhile to read through the options provided (eg.
the early distributions of blast which did not enable multi-threading by
default). If you have to install something yourself that the application depends on,
then you may need to specify some option telling =configure= where
to look for these dependancies. But hopefully you won't have to do that, as it can
be a little tricky.

*** make
The =make= program is usually invoked to compile complex source trees. =make=
reads dependancy information from a file, usually called =Makefile=, though the
name of the file it reads can be specified with the =-f= option. What make
does is to look at the tree of dependancies and if the output (eg. the
compiled binary) has an older modification date than something it depends on
then it will run a command to update the output. 

Compilation actually involves
at least two steps; the creation of object files and the linking of these
together with other libraries to create the final output. Hence the final
executable depends on the object files which depend on the individual source
files and the header files referenced within those files (don't worry too
much if this doesn't make that much sense to you; I'm only mentioning it so
that you can get a feeling of the dependancy graph). Hence if you change a
single source file, then the object file which depends on that will need to be
re-compiled, and then this has to be linked with all the other object files to
form the application. This means that you do not need to recompile every
source file everytime you change a single file.  

At this stage you do not need
to understand the Makefile syntax; and it can be pretty horrible to be
honest. However, I would suggest you have a peek inside the Makefile as you
will start to understand what's going on with time. If nothing else it can
help you to understand error messages when things go wrong.

*** make install 
Again this makes use of make to run commands specified within the
Makefile. Those commands will depend on how the =configure= script was run. If
the configure script was run correctly then this should simply copy files into
appropriate locations. If you can and wish to install globally (so that all
users can use the program) then you need to run this command as root.

** other ways
Programs are occassionally very simple; in this case you can simply copy the
executable file to your =~/bin/= directory and it will hopefully work. Ideally
the providers of the software should provide sufficient instructions (look for
a file called, README, INSTALL, or something similar), but it does happen that
they don't give you much to work with. In that case you'll need to experiment
a little. The important thing here is to try to understand the resulting error
message. Google is pretty much your best friend for this if you don't have
any friendly system admins / bioinformatics people around.

As mentioned previously you may need to set up specific environent variables.
This is usually done in the =~/.bashrc= or =~/.bash_profile= files. The specific
names of these can vary a bit from one distribution to another, but you should
be able to work it out (to see files beginning with a =.= you need to use
the =-a= option of =ls=, i.e. =ls -a=). In bash to set the value of an environment variable 
the syntax is:

#+begin_src sh
VAR=/usr/local/lib
export $VAR
#+end_src

Remember that if you modify one of these files you still need to make sure that it
is read by the shell for the changes to take effect. This can be achieved by
either sourcing the file, eg. =source ~/.bashrc=, or by logging out and in again.

Good luck, and don't be afraid of reading the manual.
* Bonus section PERL
Perl is a useful programming language whose principles can be learnt
within a short period of time allowing researchers not familiar with
programming to quickly become able to automate a variety of processes.
Although not an official acronym, Perl is often referred to as standing
for, 'Practical Extraction and Reporting Language'; and this is pretty much
what Perl makes easy.

Perl has been used extensively within the field of Bioinformatics (see
Bioperl, http://www.bioperl.org) though recently it has been overshadowed to
some extent by the use of R for statistical analyses of data and Python for
more complex scripts and programs. However, Perl remains widely used and
several of the tools you will use in this course have been written completely
in Perl, and many others use Perl for wrapper scripts[fn:: Scripts that run
check and modify input before calling other executables.]. R is incredibly
useful when you have regular data structures that can be expressed as arrays
or matrices; however it is unsuitable for describing irregular types of data
(eg.  structures of genes, etc.) where it may be necessary to iterate through
the elements of a data set. Compared to R, Perl is a much more general
programming language that can be applied to a much wider set of
problems. Python is probably a more suitable language for building bigger
applications, but Perl is hard to beat for writing the quick
throw-away scripts that are so common when handling larger data sets.

The motto of Perl is, 'There is more than one way to do it'. And in Perl
this is very true; the same logic can be expressed in a number of
different ways and masters of Perl will sometimes delight in their
ability to fit a very large amount of functionality into a small amount
of code. This is kind of neat, but can lead to code that is difficult to
understand and should not be encouraged for code that will
actually be used. The flexibility of Perl also means that it can be
difficult to read other people's code as they may use a very different
style of coding to ones own. Perl can also be quite a dangerous language
and it is often said that it gives the user more than enough rope to
hang themselves with.

** The structure of a typical script

A typical script is takes a number of arguments that are specified by the user
when invoking the script. For a script called sc1.pl and which is present in
the current working directory:

#+begin_src sh
./sc1.pl argument1 argument2
#+end_src

The words (space delimited unless escaped by =\= or quoted) following the name of the
script are arguments. They will be accessible within the script from the 
special variable =@ARGV= (see below). The arguments are often the names of files
that the script should process. The script will typically open the file or files specified
by the command and extract some information from these (eg. counting occurences and noting
locations of specific patterns within the data) and then print out a summary
of the data, either to the terminal (which can be redirected with =>= or piped to
other processes with =|=) or to output files.

One of the most simple scripts that can be written is the "hello_world" script. This does
nothing except print some text to the terminal but demonstrates the necessary
components of a script and provides a simple way to test the script.

#+begin_src perl
#!/usr/bin/perl -w

## this is a useless program that just prints a pointless
## string to STDOUT
print "hello world\n";
#+end_src

To run this script, save it as "hello_wordl.pl" and either:

#+begin_src sh
perl -w hello_world.pl
#+end_src
or:

#+begin_src sh
chmod +x hello_world.pl
./hello_world.pl
#+end_src

The script has only two lines that have any effect; the first of these
(=#!/usr/bin/perl -w=) allows it to be run directly on the command as in the
latter example. It simply tells the shell to invoke the perl interpreter when
run as an executable (the =chmod= command changes the permission of the file
to be executable). The =-w= in =perl -w= tells the interpreter to issue
warnings when it comes across weird things.

The second line (well the 5th line if you count them all) is actually the only
line of Perl code. It simply instructs the intepreter to print the "hello
world" string to =STDOUT=, which unless redirected means it will simply be
printed to the terminal. If you wished to do you could redirect this output to
another program, eg:

#+begin_src sh
./hello_world.pl | wc
#+end_src

which would simply count the lines, words and letters in "hello world".

You may have noticed the =\n= at the end of the string; this is the new-line
character; it simply tells Perl to print an end of line character after the
text. You will see more details of this later on in this guide.

Lines 3 and 4 beginning with =#= are comment lines. Text following a =#= is
usually (with a very small number of exceptions) interpreted as comments and
are ignored by the interpreter. In the examples in the following sections I
have included explanations of the code as comments. It is usually a good idea
to include comments to explain what the code is supposed to do so that you
have some idea of understanding it in the future. Even if you consider your
code to be so beautifully written that it is self-explanatory what it does,
you should still include comments as these tell you, not what the code does,
but what it's supposed to do (these can be rather different things).

** Variables in Perl

In order to handle information within a program we assign values to
variables and then manipulate these according to the flow of the
program. Perl provides three different types of variables:

-  Scalar variables: these take a single value (usually a number or some text) 
   and are denoted by a =$= prefix, eg. =$var=.

-  Arrays: these contain an ordered series of values that are accessed by their
   position. Arrays are denoted by an =@= prefix, eg. =@array=.
   Individual values are accessed as scalars, using square brackets to
   indicate the position, eg. =$array[3]= accesses the fourth element of
   =@array= (the fourth rather than the third as we count from 0).

-  Hashes (or associative arrays): these hold key-value pairs and are
   denoted by the =%= prefix, eg. =%hash=. Individual elements are again
   accessed as scalars, but this time using curly brackets, eg.
   =$hash{key}=. The key value can be anything that can be assigned to a
   scalar (numbers, text, and references).

** Assigning variables

The values of variables can be assigned directly in the program's source
code, but are more frequently assigned through the command line
arguments (see below) or by the program reading input (data or
configuration) files (see lower section). Scalars are the simplest:

#+begin_src perl
$var1='hello'; 
$var2="world";
$var3=3.14;
#+end_src

Strings (i.e. text elements) can be assigned using either single =’= or
double " quotes. The use of double quotes expands variables within the
quoted text such that:

#+begin_src perl
$var4="goodbye $var1";
#+end_src

will assign the text "goodbye world" to the variable =$var4=.
In contrast:

#+begin_src perl
$var4='goodbye $var1';
#+end_src

will assign the text 'goodbye $var1' to =$var4= (without the quotation
marks!).
Double quotes also allow escape codes such as =\n \t= to be interpreted
as newline and tab characters respectively.

Arrays can be assigned in a number of ways, occassionally directly in
the code:

#+begin_src perl
@ar1 = (1, 2, "three");
#+end_src

An empty array can also be created and then extended by adding elements.
This can be done by either using the =push= function or by using
subscripts beyond the range of the array:

#+begin_src perl
## text following a # character are treated as comments

@ar1 = (); ## creates an empty array of length 0 
push @ar1, "hello"; ##extends this array to have a length of 1

$ar1[2] = "three"; 
## the array now has a length of three, but an undefined value in the second position 
## $ar1[1]
#+end_src

In most cases, elements of an array will be assigned to values found in
input files containing the data to be analysed, rather than being
defined directly in the code as above.

Hashes (associative arrays) that store key value pairs are defined in a
similar way to arrays. Again the actual values are usually obtained from
input files, but can also be defined in the code.

#+begin_src perl
%kv1 = ();
## this creates an empty hash structure. It is actually not necessary to
## declare it, but one can directly assign elements of the hash:
$kv1{1} = "one";
$kv1{2} = "two";
$kv1{'three'} = 3;

## this hash could also have been created in a single line :
%kv1 = (1 => "one", 2 => "two", 'three' => 3);

## to access the elements of an associative array we obtain
## the keys of the hash using the keys command.

@keys = keys %kv1;
## print the first value associated with the first key:
print "$keys[0] $kv1{$keys[0]}\n";

## the \n simply defines a newline character
#+end_src


Scalars, arrays and associative arrays can be combined to create
arbitrarily complex data structures. Hence you can have hashes of arrays
and arrays of hashes and so on. To fully use more complicated data
structures requires an understanding of the reference. A reference is a
value that points to another piece of data by providing the memory
address of that data. For example, an array of hashes is encoded as an
array of references to hashes. To obtain the value of data referred to
by a reference the reference must be dereferenced. Perl has
a number of different ways in which this can be done, but these will not
be explained in depth here as it can get a bit messy. 

Semicolons: you may have noticed that in the above examples almost every
line ends with a semicolon. In Perl (and in many other languages), the
semicolon is used to denote the end of statements. This means
that single statements can be spread across several lines and that a
single line can contain a number of statements. This can greatly aid the
readability of the code.

** Data types

In the above examples we assigned values to variables without caring
about what kind of data we used. For example consider the following:

#+begin_src perl
$var1 = "one";
$var2 = 2;
$var3 = $var1 + $var2;  
#+end_src

Here we have assigned the value of =$var1= to a piece of text (which we
will refer to as a string from here on) whereas =$var2= has been
assigned a numeric value. Perl is a dynamically typed language; that
means that you do not have to explicitly define what type of value a
variable contains. This is convenient when writing a script (essentially
a small program), but this does make it easier to make mistakes in more
complicated situations. In the above example, the third line doesn't
make sense, and will generate an error. In this case it is obvious from
the code, but in most real world situations the values will be read in
from an external file produced by some other program or person in which
case finding the reason for the problem may not be so simple.

Perl essentially has three data types, strings, numeric values and
references. References are necessary for making more complex data
structures and to allow variable values to be modified by functions. As
mentioned above though, references will not be covered in much depth as
they are more suitable for a more advanced course. The string and
numerical data types are fairly straightforward, though there are a few
potential problems (common to essentially all computer programming):

- Numeric values do not have infinite precision. For example (1/3) is
  not equal to (0.1/0.3).

- Numeric values can not be arbitrarily large. On my machine the
  maximum value Perl can handle is somewhere between 1e308 and
  1e309. That's a pretty large number which you might think 
  you will never need.  However, it is smaller than the factorial of
  171, and this is something you may run across in statistical
  equations.

- Mathematical operations can result in illegal numbers, eg. 1/0. If
  your program carries out any calcuations you need to be aware of
  this and how Perl handles the resulting values.

- Text is actually not that simple. From the beginning, the end of
  lines has been encoded differently in Windows (i.e. DOS), MacOS and
  Unix. In Unix an end of line is encoded with a newline character, on
  Windows, a newline character followed by a carriage return, and on
  MacOS it might be just a carriage return (to be honest I
  forget). This can cause trouble as text files are usually written
  and read line by line (i.e.  new lines indicate a new section of
  data). The simplest way to avoid trouble is simply never to use
  Macs or Windows machines, but that can be difficult at times.

- These days text encoding is rather complicated, as it has been
  expanded to cater to a range of languages and character sets
  (eg. Arabic, Chinese, Japanese, Thai, etc..). This is not
  straightforward and several conflicting encodings have been
  developed. For bioinformatics you usually do not have to care; but
  you have to be aware of potential problems when handling text that
  contains unstructured descriptive data. Such text may contain
  names, or places written in glyphs that require Unicode
  encoding. Such descriptions may even contain characters that look
  like normal roman letters, but which have been encoded differently.
  Google, 'halfwidth fullwidth characters' to confuse yourself.

- Sorting. Numbers and strings are obviously sorted
  differently. Consider that =(12 > 8)=, but =('12' < '8')=. In the latter
  case we are comparing strings through a lexicographic comparison
  where the first character is the most significant for the
  sort. Since 8 is larger than 1, "8" is also larger than "12". In
  Perl sorting is lexicographic by default, and a numeric sort has to
  be explicitly specified. This is sometimes problematic when a mix of
  numerical and character based identifiers are used and the reason
  that you often see the following chromosome ordering:
  1,10,11,12,...,19,20,21,3,4,5,...,9,X,Y.

** Program flow: loops and conditionals

We use computer programs to automate repeated processes; that is to
carry out the same or similar operations on a large number of data
points. This is (usually) done by iterating over a collection of data
until some condition is met. That condition is often simply that we have
no more pieces of data to look at, but the condition can also be that a
solution to some problem has been found, or anything that you can think
of. This process is referred to as looping.

Similarly programs need to be able to handle the data differently
depending on what it is. This is handled by conditional statements.
Conditional statements are also used in lots of other cases including to
control loops. Consider the following statement that checks for the
equality of two variables.

#+begin_src perl
## $a and $b are two variables whose values are specified somewhere else in the program.
if($a == $b){
  ## then do something. For example increase the value of $b
  $b = $b + 1;
}
#+end_src

There are a few things to mention here. The first is the use of the ====
operator. This tests for numerical equality. It is very important not to
confuse this with the === operator which assigns values. Comparison
operators can be thought of as returning a TRUE or a FALSE value. If a
TRUE value is obtained then the conditional statement is carried out,
and if FALSE not. Perl doesn't actually have explicit TRUE and FALSE
values, but any non-0 value is considered as TRUE and a value of 0 is
considered as FALSE. To confuse things the use of the assignment
operator returns the value that was assigned and this can cause some
rather specific problems. Consider:

#+begin_src perl
$a = ($b = 10);
## $a is now assigned to the value of 10

## this conditional statement will always evaluate to TRUE
if( $a = 25 ){
  ## this will always be executed
}

## but this will never evaluate to TRUE
if($a = 0){
  ## this part of the program will never be reached
}
#+end_src

The second thing to mention is the use of the curly brackets ({and}). In
Perl (and quite a few other programming languages) these are used to
break the code up into blocks of code that can be conditionally executed
(or looped over, which is kind of conditional). In Perl, blocks of code
can have their own scope by using the =my= keyword. This means that a
variable which is defined within a block of code is not visible outside
of that block of code. This is very useful for more complicated programs
where it is easy to accidentally use the same variable names to represent
different properties.
Consider the following snippet:

#+begin_src perl
## We start in the global scope. Variables defined here will be visible and modifiable
## anywhere within the main body of the code (though not in external functions).

$a = 10;
{
  $a = 20;
}

print "a is $a \n";
## will print 20. However if we do:

{
  my $a = 30;
  ## $a will be equal to 30 only within this block of code
}

print "a is now $a \n";
## does not print 30, as $a was declared using the
## my keyword.
#+end_src

It is good practice to use =my= and the related =our= keyword throughout
the code as it will make it easier to catch a range of different types
of errors. This can be enforced by =use strict;=. Google for more!

Looping can be used if, for example you have an array of values that you wish to
obtain the mean value of. To do this we wish to find the sum of the
values and divide by the length of the array. As always in Perl there
are a number of ways in which this can be done:

#+begin_src perl
## @ar is an array of values specified somewhere else in the program.
## ++ is an increment operator that increases the value of its operand
## by one each time it is called.
## += is an increment operator that increases the value of its left operand
## by the value of its right operand.

## to loop through the values we can use a classic for loop:
$sum = 0;
for( $i=0; $i < @ar; $i++){
  $sum += $ar[$i];
}

## this will set the value of $i to 0, carry out the operation in the block
## following the for statement, then increment (increase) the value of
## $i by 1 and repeat as long as $i is less than the scalar value of
## @ar (which evaluates to the length of the array).

$mean = $sum / @ar;
## when an array variable is used in an expression it can can evaluate to either the array itself
## or to a scalar value equal to its length. When it's not clear as to whether the scalar or array
## value is indicated, the scalar value can be enforced by the scalar function.

## We can also use a range specified loop and make use of the fact that in Perl
## $#ar will evaluate to the higest index of an array (i.e. the length minus one)

for $i(0..$#ar){
  $sum += $ar[$i];
}

## we can also use a similar expression;
for $v(@ar){
  $sum += $v;
}

## alternatively we can use a while loop by specifying the index variable outside
## of the loop statement;
$i = 0;
while($i < @ar){
  $sum += $ar[$i];
  $i++;
}
#+end_src


These are not the only ways in which you can loop through values or data
structures, but they probably represent the most common usages.

** Reading and writing data

To read or write from a file we use a filehandle. This is just an
identifier associated with the file and the reading or writing process.
To write to a file we usually use the =print= function. Using =print=
without specifying a filehandle will lead to the text being printed to
STDOUT. In most cases this means your terminal screen, but STDOUT can
also be piped to other processes as demonstrated previously in this
guide. To open a text file and read a line at a time:

#+begin_src perl
## we wish to read from a file specified by the variable $fname

open(IN, $fname) || die "unable to open $fname $!\n";
## here IN becomes specified as the filehandle (This is one of the few cases
## where we use an undecorated string literal as an identifier).
## The second half of the statement uses the '||' operator which simply means 'or'.
## If we are unable to open the file then the program will print out the warning statement
## following die and exit. $! is a magic variable that contains the error string.

## to read all of the lines we can make use of a while loop
while(<IN>){
  ## this will assign the text of each line to another magical variable, $_
  ## we can print this out to STDOUT by calling
  print;   ## without arguments this prints $_ to STDOUT
  
  ## normally we would do something useful first by processing the data in the line.
  ## but more of that later.
}
#+end_src



To write to a file we also use open, but modify the filename to indicate
that we wish to write to a new file by prefixing the name with a '>'
character. If a file of the same name exists it will be overwritten. If
we wish to append to an existing file we can use '>>'.

#+begin_src perl
## given that we wish to write something to a file specified by the
## $fname variable.
open(OUT, ">$fname") || die "unable to open $fname $!\n";
## write out the multiplication table (1..10) to the file
## first write out some column headers
for $i(1..10)\{
  print OUT "\t$i";
}
print OUT "\n";

for $i(1..10){
  print OUT $i;
  for $j(1..10){
    print OUT "\t", $i * $j;
  }
  print OUT "\n";
}

close OUT;
#+end_src

** Regular Expressions

You have already come across regular expressions in this course; they
are used by a number of Unix utilities like grep. The Perl
implementation of regular expressions is perhaps one of the best and
most powerful ones available and a large part of the power of Perl comes
through its ability to make use of regular expressions.

As mentioned previously regular expressions are used to identify matches
to generalised text patterns in strings. There are a very large number
of tutorials on how to use regular expressions in Perl available on the
net and we will only provide a very short introduction here.

In Perl, regular expression matching makes use of the ==~= operator,
where the left operand contains the text to searched for matches to the
pattern given by the right operand. Some examples:

#+begin_src perl
## The left operand is usually a variable, but for clarity we'll use
## plain strings.

## The regular expression is usually written as follows:
## "some string to be tested" =~ m/ a regular expression /
##
## the character immediately following the m delimits the regular expression. If you wish to
## include this character within the regular expression it will need to be escaped by placing
## a \ in front of it. For regular pattern matching you do not need to specify the
## m if you are using the forward slash as the delimiter. This is the most common way to write it.
## So to check if an expression looks like the name of a Hox gene we can do:

"HoxA3" =~ /hox[a-z][0-9]+/;

## Normal characters are matched directly, characters within square brackets [] represent a character
## class (any character specified will allow a match). In the above example, the regular expression
## will fail to recognise the left operand since the regular expression is case sensitive. To overcome
## this we can do:

"HoxA3" =~ /hox[a-z][0-9]+/i;

## we could also specify a character class at each position, but this would be ugly:
"HoxA3" =~ /[hH][oO][xX][A-z][0-9]+/;

## which reads as: h OR H followed by o OR O followed by x OR X followed by a single character between A and z
## followed by at least one number. But that is pretty ugly.

## if you wish to use a different delimiter, like the # character you can write it like:
"HoxA3" =~ m#hox[a-z][0-9]+#i

## this can be useful when trying to match directory names that contain lots of forward slashes.

## The above expressions on their own do nothing as we do not make use of the returned value
## To actually use a regular expression we make use of conditionals, eg...

if("HoxA3" =~ /hox[a-z][0-9]+/i){
  ## we have Hox gene, do something here..
}
## to substitute words we can use the s modifier. We may wish to substitute spaces within a
## a string with underscores.
$string = "Goodbye cruel World";
$string =~ s/ /_/g;

## here we also make use of the g (global) modifier to replace all instances rather than just the first
## match.
#+end_src

Regular expressions make use of a number of special characters and
modifiers to represent textual patterns. The characters represent
character classes, followed by a modifier specifying how many matches
should be present to give a match. In Perl, the most widely used special
characters are:

-  =.= The dot. This matches any character.

-  =\d= A numeric character. Equivalent to specifying [0-9].

-  =\s= A space.

-  =\S= Non space characters.

-  =\w= Word characters (alpha numeric and some others).

-  =\b= Word boundaries (tabs, spaces, newlines, punctuation).

-  =\t= Tab characters.

A character may be followed by a modifier specifying how many times the
character should be present in the text.

-  =+= 1 or more.

-  =*= 0 or more.

-  =?= 0 or 1.

-  ={N}= Exactly N times.

-  ={n..N}= n to N times.

Other modifiers can be used to specify where a match should be present:
=^= and =$= specify the beginning and end of lines respectively. Note
that =^= inside a character class indicates an inverted character class
(matches characters not present in the class).

Regular expressions can also be used to capture specific subsections of
text. A very common example would be to extract a sequence identifier
from a fasta file. This can easily be done in Perl.

#+begin_src perl
## $line contains a line from a file. Identifiers begin with the > character.
if( $line =~ /^>(\S+)/ ){
    $seqId = $1;
}
## if brackets are used in the regular expression, the values matching within the brackets
## will be assigned to variables $1 - $9. (Ordered from left to right). If you wish to match
## brackets you will need to escape them with backslashes.
#+end_src

There's a lot more to regular expressions than this, but this may be enough to get
started with.

** Various operators

Operators are symbols that denote specific operations; like regular
expression matching or regular mathematical operations. We have already
come across a few of these, but there are more (and the following list
is not complete).

- =+= The addition operator. Returns the sum of the left and right
  operand.

- =-= The subtraction operator.

- =++= The auto-increment operator. Increases the value of its single
  operand by 1. There are in fact two different increment operators;
  post-increment =$v++= and pre-increment =++$v=. The former increments
  the value after other operations, the latter before. Consider the
  difference between =$i=5; print $i++;= and =$i=5; print ++$i;=.

- =--= The auto-decrement operator. Opposite of auto-increment.

- =+== The increment operator. Increases the value of its left operand
  by the value of its right operand.

- =-== The decrement operator. Opposite of the increment operator.

- =*= Multiplication.

- =/= Division.

- =*== Sets the value of its left operand to the product of the left
  and right operands. Identical to =$left = $left * $right=.

- =/== As above but for division.

- =**= Exponentiation. Returns the value of the left operand to the
  power of the right operand.

- =.= String concatenation. Concatenates left and right operands.

- =.== Concatenates right operand to left operand.

- ==== Numerical equality operator. Returns TRUE if the value of the
  left and right operands are equal. Causes an error if either
  operand is not numerical.

- =!== Numerical inequality operator. Returns TRUE if the value of the
  left and right operands are not equal. Causes an error if either
  operand is not numerical.

- =eq= String equality operator. Returns TRUE if the strings specified
  by the left and the right hand operators are the same.

- =ne= String inequality operator. Returns TRUE if the strings specified
  by left and right hand operators are not the same.
- =>= Numerical greater than. Returns true if left operator is larger than
  the right operator.

- =<= Numerical less than. Opposite of above.
 
- =>== Numerical greater than or equal to.

This is an incomplete list, but is sufficient to do rather a lot with. Note
that some operators should be used with numerical values and others with strings
(pieces of text). Using the wrong data types will sometimes raise errors, but
can also result in the program silently doing something unexpected (which is the
worst kind of behaviour as it can result in corrupt output).

** A somewhat useful example

As an example of something potentially useful we can write a short script
that reads in sequences from a fasta file and identifies sequences that
contain a specific pattern within the first N bases. To do this we'll
make use of most of the techniques outlined above, but we'll also need
to be able to work out options specified by the user on the command
line. The arguments specified to a Perl script are assigned to a special
array called =@ARGV=, and we'll make use of this array to work out what
the user wants to do.

The following segment contains a full script that you should be able to
run, using the ./scriptname invocation.

#+begin_src perl
#!/usr/bin/perl -w

## the first line is not really a comment, but is used to make the shell invoke the perl interpreter on the
## script.

## first check the command line arguments to make sure that the user has specified three arguments.
## the first argument should give the name of the fasta file containing the sequences to be searched,
## the second argument the pattern to look for, and the third argument the maximum distance from the
## beginning of the sequence.

if(@ARGV != 3)\{
  die "usage: script_name fasta_file pattern max_distance_from_edge \n";
}

## we could also use regular expressions to check if the arguments are of the correct type

$seqId = "";

## open the fasta file and read line by line.
open(IN, $ARGV[0]) || die "unable to open $ARGV[0] $!\n";
while(<IN>){
  chomp; ## this removes the end of line character from $_
  ## does the line look like it contains a sequence identifier?
  if( $_ =~ /^>(\S+)/ ){
    $seqId = $1;
    next;  ## go to the next iteration of the loop
  }
  ## if we have defined a sequence identifer, we will just assume that the rest of the text contains sequence
  if(length($seqId)){
    $seq{$seqId} .= $_;   ## extends the length of, or initialises a hash entry
  }
}

## We should now have read all of the sequences into an associative array where the keys are the sequence
## identifiers. We now go through the sequences and check for the pattern.
## The identifiers of sequences which match are printed out to STDOUT.
## We could also print the matching sequences if we wished.

for $seqId(keys %seq){
  if( $seq{$seqId} =~ /^.{0,$ARGV[2]}$ARGV[1]/ ){
    print "$seqID\n";
  }
}

## end of the script!
#+end_src

This script probably has a few bugs in it. Working out where those bugs
are is a pretty good exercise for honing your Perl skills. Note also
that bad command line arguments can cause all sorts of problems as the
script does not check the arguments given. The script is quite useful
though, as you can use it as a sort of configurable grep to learn more
about regular expressions in Perl.

Be aware that this is not a very memory efficient way of solving the
problem as all of the sequences are read into memory before any
processing is done. This is not only memory intensive, but it's also
slower. It's been written this way to show the use of hashes and to keep
it reasonably short. I've also avoided using custom functions as I've
not included anything about how to write your own functions (subroutines
in Perl). How to write your own functions is probably the first thing
you should look at after this introduction if you wish to start using
Perl seriously.

Good luck with Perl!

* Recommended books
- [[http://unixandperl.com/][Unix and Perl to the Rescue]]
- [[http://www.staff.hs-mittweida.de/~wuenschi/doku.php?id=rwbook2][Computational Biology]]
* Unix cheat sheet
** FILE system
#+begin_latex
\small
#+end_latex

#+ATTR_LATEX: :mode table :align p{4cm}p{10cm}
| Command               | Meaning                                                                                               |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =cd DIR=              | change directory to DIR                                                                               |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =cd ..=               | go up one directory                                                                                   |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =cd ~=                | to to your home directory                                                                             |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =pwd=                 | show present working directory                                                                        |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =ls=                  | list items in current directory                                                                       |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =ls -a=               | list all items, including hidden ones                                                                 |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =ls -lhcrt=           | list all items in long, human-readable format and sort in reverse order by modification time          |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =ls -F=               | list all items in current directory and show directories with a slash and executables with a star     |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =tree  -C=            | print hierarchical structure of your FILEs and directories (color-coded)                              |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =tree -d=             | print hierarchical structure of all subdirectories                                                    |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =tree -sh=            | print hierarchical structure of FILEs and directories with sizes (-s) in a human-readable format (-h) |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =mkdir directoryname= | make new directory named directoryname                                                                |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =mv FILE1 FILE2=      | rename FILE1 to FILE2                                                                                 |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =mv FILE1 ../FILE2=   | move FILE1 one directory up                                                                           |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =cp FILE1 FILE2=      | copy FILE1 and save it as FILE2                                                                       |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =rm FILE=             | remove FILE                                                                                           |
|-----------------------+-------------------------------------------------------------------------------------------------------|
| =rm -r DIRECTORY=     | remove directory and all of its contents                                                              |

** Opening FILEs and extracting information
#+ATTR_LATEX: :mode table :align p{4cm}p{10cm}
| Command                                 | Meaning                                                                                  |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =less FILE=                             | open FILE and scroll through it line by line                                             |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =wc -l -w -m  FILE=                     | counting lines, words, and characters in FILE                                            |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =grep "pattern" FILE=                   | print lines from FILE that contain "pattern"                                             |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =grp -v "pattern" FILE=                 | print lines from FILE that do not contain "pattern"                                      |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =cat FILE > FILE2=                      | write the content of FILE to FILE2                                                       |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =cat FILE >> FILE2=                     | append the content of FILE to FILE2                                                      |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =sed -n 11,12p FILE=                    | extract lines 11 to 12 from FILE                                                         |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =awk -F "\t" '$1 > 20 {print $0}' FILE= | Print all columns of a line ($0) in FILE if the value in column 1 ($1) is bigger than 20 |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =unzip FILE.zip=                        | unzip the zip-compressed FILE                                                            |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =gunzip FILE.gz=                        | unzip the gz-compressed FILE                                                             |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =sort -n  NUMBERS=                      | sort a row of NUMBERS numerically                                                        |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =uniq -c  FILE=                         | count unique lines in FILE                                                               |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =nano FILE=                             | open FILE on the command-line                                                            |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =xdg-open  FILE=                        | open FILE with the standard program for its file type                                    |
|-----------------------------------------+------------------------------------------------------------------------------------------|
| =eog FILE=                              | open FILE (which is a figure) with the Eye of Gnome graphics viewer program              |

** Data transfer
#+ATTR_LATEX: :mode table :align p{4cm}p{10cm}
| Command                            | Meaning                                                                                                                                            |
|------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------|
| =rsync --progress -avz SRC DEST=   | transfer from SRC to DEST, show the progress while FILEs are compressed during the transfer in archive mode (including recursing into directories) |
|------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------|
| =rsync FILE user@host://home/usr/= | transfer FILE to the folder /home/usr on the remote server user@host                                                                               |
|------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------|
| =rsync -avz directory/ DEST=       | transfer all FILEs saved in directory to DEST                                                                                                      |
|------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------|
| =rsync -avz directory DEST=        | create the folder directory in DEST and transfer all FILEs in this directory                                                                       |
|------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------|
| =scp -r SRC DEST=                  | transfer all FILEs in SRC to DEST                                                                                                                  |
|------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------|
| =scp FILE DEST=                    | transfer FILE to DEST                                                                                                                              |

** Executing scripts and programs
#+ATTR_LATEX: :mode table :align p{4cm}p{10cm} 
| Command                  | Meaning                                                                  |
|--------------------------+--------------------------------------------------------------------------|
| =nohup ... &=            | execute ... in the background                                            |
|--------------------------+--------------------------------------------------------------------------|
| =nohup ... > FILE.txt &= | execute ... in the background and redirect output to FILE.txt            |
|--------------------------+--------------------------------------------------------------------------|
| =ps -p ID=               | print the status of a process with the specified process-ID              |
|--------------------------+--------------------------------------------------------------------------|
| =kill ID=                | stop the process witht the specified process-ID                          |
|--------------------------+--------------------------------------------------------------------------|
| =pkill NAME=             | stop all processes with NAME (NAME could be for example 'R' or 'python') |
|--------------------------+--------------------------------------------------------------------------|
| =top=                    | provides an ongoing look at processor activity in real time              |

** Networking
#+ATTR_LATEX: :mode table :align p{4cm}p{10cm}
| Command            | Meaning                                                                                                   |
|--------------------+-----------------------------------------------------------------------------------------------------------|
| =ssh user@host=    | connect to host as user                                                                                   |
|--------------------+-----------------------------------------------------------------------------------------------------------|
| =ssh -X user@host= | connect to host as user with X11 forwarding enabled (you can open programs with graphical user interface) |

** Help
#+ATTR_LATEX: :mode table :align p{4cm}p{10cm}
| Command          | Meaning                                           |
|------------------+---------------------------------------------------|
| =command --help= | Lists the options for command                     |
|------------------+---------------------------------------------------|
| =man command=    | opens the manual page for command (exit with 'q') |

** Tricks

Pipe output from one command with =|= as input to another command.

#+ATTR_LATEX: :mode table :align p{4cm}p{10cm}
| Command             | Meaning                                                                                       |
|---------------------+-----------------------------------------------------------------------------------------------|
| =TAB key=           | auto-completion of commands, FILE names etc.                                                  |
|---------------------+-----------------------------------------------------------------------------------------------|
| =UP or DOWN arrows= | move through the history of your commands                                                     |
|---------------------+-----------------------------------------------------------------------------------------------|
| =history=           | Get overview of the commands you have used                                                    |
|---------------------+-----------------------------------------------------------------------------------------------|
| =*=                 | Allows to generalize file names. For example, *fasta refers to all fasta files in a directory |






